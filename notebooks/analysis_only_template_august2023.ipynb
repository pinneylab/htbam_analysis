{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis Template\n",
    "WIP Analysis template, adapted from Margaux's notebook from 07/12/2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#enables autoreloding of modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "from copy import deepcopy\n",
    "\n",
    "import skimage\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.stats\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "from pathlib import Path \n",
    "from htbam_analysis.htbam_db_api import LocalHtbamDBAPI\n",
    "\n",
    "#Import Kinetics Package for line fitting:\n",
    "from kinetics import *\n",
    "\n",
    "#Configuration settings for pandas and seaborn\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "sns.set(style='ticks', context='paper', font_scale=1.2, rc={\"lines.linewidth\": 1.2})\n",
    "\n",
    "#enable inline plotting of matplotlib figures\n",
    "%matplotlib inline\n",
    "\n",
    "#set the figure format to SVG\n",
    "%config InlineBackend.figure_format = 'svg'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1. Connect DB Api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: parsing concentration from string\n",
      "Warning: parsing concentration from string\n",
      "Warning: parsing concentration from string\n",
      "Warning: parsing concentration from string\n",
      "Warning: parsing concentration from string\n",
      "Warning: parsing concentration from string\n",
      "Warning: parsing concentration from string\n",
      "Warning: parsing concentration from string\n",
      "Warning: parsing concentration from string\n",
      "Warning: parsing concentration from string\n",
      "Warning: parsing concentration from string\n"
     ]
    }
   ],
   "source": [
    "from htbam_analysis.htbam_db_api import LocalHtbamDBAPI\n",
    "\n",
    "root = '../test/test_data/'\n",
    "db_conn = LocalHtbamDBAPI(standard_curve_data_path= root + 'd2_5_StandardSeries_Analysis.csv.bz2', standard_name=\"NADPH std curve\", standard_type=\"NADPH\", standard_units=\"uM\",\n",
    "                         kinetic_data_path= root+ 'd2_TitrationSeries_Analysis.csv.bz2', kinetic_name=\"ADP kinetics curve\", kinetic_type=\"ADP\", kinetic_units=\"uM\")\n",
    "\n",
    "### TODO: Still want the following data in the database:\n",
    "# date (and time?) collected\n",
    "# operator name\n",
    "# Add additional descriptors\n",
    "# substrate_name\n",
    "# setup(?) and device_num\n",
    "# width/height\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Format of DB:\n",
    "DB\n",
    "- **chamber_metadata**\n",
    "    - '1,1'\n",
    "        - 'id'                  'organism_ADK'\n",
    "        - 'radius_chamber'      35.0\n",
    "        - 'x_center_chamber'    31.0\n",
    "        - 'y_center_chamber'    43.0\n",
    "        - 'xslice'              '(6758, 6805)'\n",
    "        - 'yslice'              '(6704, 6804)'\n",
    "    - ...\n",
    "    - '32,56' ...\n",
    "- **runs**\n",
    "    - 'standard_0'\n",
    "        - 'name'            'NAPDH_std_curve'\n",
    "        - 'type'            'NAPDH'\n",
    "        - 'conc_unit'       'uM'\n",
    "        - 'assays':\n",
    "            - 0:\n",
    "                - 'conc'\n",
    "                - 'time_s'\n",
    "                - 'chambers'\n",
    "                    - '1,1'\n",
    "                    - ...\n",
    "                    - '32,56' ...\n",
    "            - ...\n",
    "            - 6: ...\n",
    "        - 'analyses':\n",
    "            - 'linear_regression':\n",
    "                - 'chambers':\n",
    "                    - '1,1':\n",
    "                        - slope:\n",
    "                        - intercept:\n",
    "                        - r_value:\n",
    "                        - p_value: \n",
    "                        - std_err:\n",
    "                    - ...\n",
    "                    - '32,56'...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "chamber_metadata: \n",
      "\t{\n",
      "\t1,1: \n",
      "\t\t{\n",
      "\t\tid: M_caps_ADK\n",
      "\t\tx_center_chamber: 35.0\n",
      "\t\ty_center_chamber: 51.0\n",
      "\t\tradius_chamber: 35.0\n",
      "\t\txslice: (395, 495)\n",
      "\t\t...\n",
      "\t\t}\n",
      "\t1,2: \n",
      "\t\t{\n",
      "\t\tid: P_syri_ADK\n",
      "\t\tx_center_chamber: 35.0\n",
      "\t\ty_center_chamber: 51.0\n",
      "\t\tradius_chamber: 34.0\n",
      "\t\txslice: (510, 610)\n",
      "\t\t...\n",
      "\t\t}\n",
      "\t1,3: \n",
      "\t\t{\n",
      "\t\tid: L_reut_ADK\n",
      "\t\tx_center_chamber: 37.0\n",
      "\t\ty_center_chamber: 51.0\n",
      "\t\tradius_chamber: 37.0\n",
      "\t\txslice: (626, 726)\n",
      "\t\t...\n",
      "\t\t}\n",
      "\t1,4: \n",
      "\t\t{\n",
      "\t\tid: G_ther_ADK\n",
      "\t\tx_center_chamber: 37.0\n",
      "\t\ty_center_chamber: 49.0\n",
      "\t\tradius_chamber: 36.0\n",
      "\t\txslice: (742, 842)\n",
      "\t\t...\n",
      "\t\t}\n",
      "\t1,5: \n",
      "\t\t{\n",
      "\t\tid: bmADK\n",
      "\t\tx_center_chamber: 35.0\n",
      "\t\ty_center_chamber: 49.0\n",
      "\t\tradius_chamber: 34.0\n",
      "\t\txslice: (858, 958)\n",
      "\t\t...\n",
      "\t\t}\n",
      "\t...\n",
      "\t}\n",
      "runs: \n",
      "\t{\n",
      "\tstandard_0: \n",
      "\t\t{\n",
      "\t\tname: NADPH std curve\n",
      "\t\ttype: NADPH\n",
      "\t\tconc_unit: uM\n",
      "\t\tassays: \n",
      "\t\t\t{\n",
      "\t\t\t0: \n",
      "\t\t\t\t{\n",
      "\t\t\t\tconc: 3.90625\n",
      "\t\t\t\ttime_s: [0]\n",
      "\t\t\t\tchambers: \n",
      "\t\t\t\t\t{\n",
      "\t\t\t\t\t1,1: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [188096.0]\n",
      "\t\t\t\t\t\tstd_chamber: [78.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,10: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [228483.0]\n",
      "\t\t\t\t\t\tstd_chamber: [99.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,11: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [224214.0]\n",
      "\t\t\t\t\t\tstd_chamber: [84.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,12: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [196095.0]\n",
      "\t\t\t\t\t\tstd_chamber: [80.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,13: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [234481.0]\n",
      "\t\t\t\t\t\tstd_chamber: [253.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t...\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t}\n",
      "\t\t\t1: \n",
      "\t\t\t\t{\n",
      "\t\t\t\tconc: 7.8125\n",
      "\t\t\t\ttime_s: [0]\n",
      "\t\t\t\tchambers: \n",
      "\t\t\t\t\t{\n",
      "\t\t\t\t\t1,1: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [240692.0]\n",
      "\t\t\t\t\t\tstd_chamber: [88.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,10: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [259851.0]\n",
      "\t\t\t\t\t\tstd_chamber: [105.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,11: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [267881.0]\n",
      "\t\t\t\t\t\tstd_chamber: [94.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,12: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [229483.0]\n",
      "\t\t\t\t\t\tstd_chamber: [85.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,13: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [266559.0]\n",
      "\t\t\t\t\t\tstd_chamber: [257.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t...\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t}\n",
      "\t\t\t2: \n",
      "\t\t\t\t{\n",
      "\t\t\t\tconc: 15.625\n",
      "\t\t\t\ttime_s: [0]\n",
      "\t\t\t\tchambers: \n",
      "\t\t\t\t\t{\n",
      "\t\t\t\t\t1,1: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [330890.0]\n",
      "\t\t\t\t\t\tstd_chamber: [104.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,10: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [358876.0]\n",
      "\t\t\t\t\t\tstd_chamber: [119.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,11: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [367405.0]\n",
      "\t\t\t\t\t\tstd_chamber: [106.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,12: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [349277.0]\n",
      "\t\t\t\t\t\tstd_chamber: [103.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,13: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [368497.0]\n",
      "\t\t\t\t\t\tstd_chamber: [264.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t...\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t}\n",
      "\t\t\t3: \n",
      "\t\t\t\t{\n",
      "\t\t\t\tconc: 31.25\n",
      "\t\t\t\ttime_s: [0]\n",
      "\t\t\t\tchambers: \n",
      "\t\t\t\t\t{\n",
      "\t\t\t\t\t1,1: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [644967.0]\n",
      "\t\t\t\t\t\tstd_chamber: [141.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,10: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [643179.0]\n",
      "\t\t\t\t\t\tstd_chamber: [147.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,11: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [681549.0]\n",
      "\t\t\t\t\t\tstd_chamber: [138.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,12: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [656808.0]\n",
      "\t\t\t\t\t\tstd_chamber: [134.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,13: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [655309.0]\n",
      "\t\t\t\t\t\tstd_chamber: [272.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t...\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t}\n",
      "\t\t\t4: \n",
      "\t\t\t\t{\n",
      "\t\t\t\tconc: 125.0\n",
      "\t\t\t\ttime_s: [0]\n",
      "\t\t\t\tchambers: \n",
      "\t\t\t\t\t{\n",
      "\t\t\t\t\t1,1: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [2990428.0]\n",
      "\t\t\t\t\t\tstd_chamber: [327.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,10: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [2682125.0]\n",
      "\t\t\t\t\t\tstd_chamber: [289.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,11: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [2997113.0]\n",
      "\t\t\t\t\t\tstd_chamber: [323.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,12: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [3050228.0]\n",
      "\t\t\t\t\t\tstd_chamber: [293.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,13: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [2964056.0]\n",
      "\t\t\t\t\t\tstd_chamber: [399.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t...\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t}\n",
      "\t\t\t...\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\tkinetics_0: \n",
      "\t\t{\n",
      "\t\tname: ADP kinetics curve\n",
      "\t\ttype: ADP\n",
      "\t\tconc_unit: uM\n",
      "\t\tassays: \n",
      "\t\t\t{\n",
      "\t\t\t0: \n",
      "\t\t\t\t{\n",
      "\t\t\t\tconc: 1000.0\n",
      "\t\t\t\ttime_s: [0, 107, 1257, 143, 1557, 179, 1857, 214, 250, 286, 322, 357, 36, 417, 477, 537, 597, 657, 71, 957]\n",
      "\t\t\t\tchambers: \n",
      "\t\t\t\t\t{\n",
      "\t\t\t\t\t1,1: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [5706550.0, 6111047.0, 11687580.0, 6252476.0, 12771839.0, 6496490.0, 13601648.0, 6560664.0, 6807164.0, 6904110.0, 7100560.0, 7285440.0, 5779893.0, 7742776.0, 8097891.0, 8364556.0, 8657411.0, 8870927.0, 5918860.0, 10368417.0]\n",
      "\t\t\t\t\t\tstd_chamber: [387.0, 478.0, 1495.0, 513.0, 1694.0, 548.0, 1861.0, 583.0, 627.0, 658.0, 696.0, 724.0, 409.0, 796.0, 853.0, 909.0, 969.0, 1015.0, 441.0, 1271.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,10: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [993859.0, 6815357.0, 21599775.0, 8271935.0, 22307698.0, 9475365.0, 22550946.0, 10476613.0, 11408539.0, 12161098.0, 12919157.0, 13566534.0, 2989408.0, 14696183.0, 15726882.0, 16494785.0, 17213104.0, 17816508.0, 5088504.0, 20274702.0]\n",
      "\t\t\t\t\t\tstd_chamber: [219.0, 1210.0, 3669.0, 1461.0, 3772.0, 1669.0, 3801.0, 1843.0, 2000.0, 2136.0, 2265.0, 2370.0, 546.0, 2558.0, 2727.0, 2859.0, 2975.0, 3078.0, 908.0, 3469.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,11: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [1019894.0, 1283020.0, 5306931.0, 1424235.0, 6137206.0, 1558000.0, 6822833.0, 1673322.0, 1811411.0, 1913603.0, 2042143.0, 2168285.0, 1088892.0, 2451438.0, 2723241.0, 2939916.0, 3129633.0, 3308864.0, 1170345.0, 4381145.0]\n",
      "\t\t\t\t\t\tstd_chamber: [211.0, 261.0, 845.0, 283.0, 961.0, 301.0, 1071.0, 322.0, 342.0, 361.0, 378.0, 399.0, 222.0, 438.0, 473.0, 502.0, 534.0, 563.0, 241.0, 714.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,12: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [1018086.0, 5533008.0, 22021641.0, 6805264.0, 23610365.0, 7888695.0, 24491342.0, 8849341.0, 9713049.0, 10436485.0, 11202118.0, 11878670.0, 2472329.0, 13062224.0, 14126802.0, 14966136.0, 15785480.0, 16511326.0, 4099259.0, 19723086.0]\n",
      "\t\t\t\t\t\tstd_chamber: [217.0, 1003.0, 3773.0, 1225.0, 4027.0, 1413.0, 4162.0, 1577.0, 1730.0, 1860.0, 1986.0, 2105.0, 465.0, 2302.0, 2478.0, 2621.0, 2759.0, 2880.0, 748.0, 3411.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,13: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [893434.0, 1562758.0, 8276068.0, 1854220.0, 9517212.0, 2115900.0, 10547386.0, 2365359.0, 2602063.0, 2817998.0, 3057931.0, 3296254.0, 1076345.0, 3749090.0, 4181894.0, 4546259.0, 4891835.0, 5217944.0, 1289226.0, 6855831.0]\n",
      "\t\t\t\t\t\tstd_chamber: [321.0, 409.0, 1345.0, 441.0, 1525.0, 480.0, 1676.0, 514.0, 545.0, 581.0, 613.0, 647.0, 339.0, 705.0, 766.0, 816.0, 866.0, 915.0, 367.0, 1147.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t...\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t}\n",
      "\t\t\t1: \n",
      "\t\t\t\t{\n",
      "\t\t\t\tconc: 125.0\n",
      "\t\t\t\ttime_s: [0, 107, 1258, 143, 1558, 179, 1858, 214, 250, 286, 322, 358, 36, 418, 478, 538, 598, 658, 71, 958]\n",
      "\t\t\t\tchambers: \n",
      "\t\t\t\t\t{\n",
      "\t\t\t\t\t1,1: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [8136071.0, 8779072.0, 12297277.0, 8973313.0, 12711744.0, 9135669.0, 12874143.0, 9337468.0, 9460129.0, 9571357.0, 9656313.0, 9815460.0, 8274315.0, 10101405.0, 10303423.0, 10462064.0, 10687599.0, 10734019.0, 8517578.0, 11716124.0]\n",
      "\t\t\t\t\t\tstd_chamber: [487.0, 511.0, 755.0, 519.0, 795.0, 531.0, 801.0, 539.0, 552.0, 565.0, 576.0, 584.0, 488.0, 604.0, 615.0, 635.0, 649.0, 658.0, 498.0, 715.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,10: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [625410.0, 3474955.0, 6217674.0, 3918941.0, 6377513.0, 4242168.0, 6363578.0, 4512960.0, 4710216.0, 4847984.0, 4966483.0, 5048604.0, 1780525.0, 5245305.0, 5388851.0, 5491937.0, 5573753.0, 5632528.0, 2794202.0, 6016738.0]\n",
      "\t\t\t\t\t\tstd_chamber: [195.0, 418.0, 639.0, 456.0, 647.0, 484.0, 643.0, 510.0, 528.0, 541.0, 551.0, 562.0, 277.0, 578.0, 588.0, 597.0, 601.0, 607.0, 353.0, 629.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,11: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [540378.0, 738863.0, 2930814.0, 807846.0, 3332516.0, 866794.0, 3533592.0, 955709.0, 1045780.0, 1095217.0, 1154148.0, 1224701.0, 592045.0, 1363423.0, 1517568.0, 1633090.0, 1759191.0, 1836781.0, 680949.0, 2467240.0]\n",
      "\t\t\t\t\t\tstd_chamber: [132.0, 156.0, 345.0, 165.0, 376.0, 170.0, 396.0, 181.0, 191.0, 195.0, 199.0, 207.0, 140.0, 221.0, 236.0, 244.0, 254.0, 261.0, 152.0, 310.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,12: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [567603.0, 3128404.0, 6835637.0, 3622077.0, 7062621.0, 4005722.0, 7068715.0, 4325448.0, 4580633.0, 4786534.0, 4959712.0, 5110547.0, 1525622.0, 5365631.0, 5581630.0, 5739273.0, 5883106.0, 5966593.0, 2458335.0, 6557399.0]\n",
      "\t\t\t\t\t\tstd_chamber: [137.0, 369.0, 685.0, 416.0, 695.0, 455.0, 701.0, 485.0, 509.0, 529.0, 543.0, 561.0, 225.0, 585.0, 599.0, 614.0, 626.0, 631.0, 305.0, 669.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,13: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [414467.0, 950454.0, 4466705.0, 1143795.0, 4952392.0, 1311376.0, 5244840.0, 1483921.0, 1649943.0, 1766141.0, 1906750.0, 2032047.0, 562480.0, 2279292.0, 2516475.0, 2703785.0, 2876810.0, 3023237.0, 763219.0, 3857929.0]\n",
      "\t\t\t\t\t\tstd_chamber: [257.0, 296.0, 515.0, 311.0, 538.0, 330.0, 561.0, 334.0, 347.0, 354.0, 364.0, 372.0, 273.0, 380.0, 401.0, 416.0, 423.0, 428.0, 286.0, 481.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t...\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t}\n",
      "\t\t\t2: \n",
      "\t\t\t\t{\n",
      "\t\t\t\tconc: 15.625\n",
      "\t\t\t\ttime_s: [0, 107, 1256, 142, 1556, 178, 1856, 214, 250, 285, 321, 35, 356, 416, 476, 536, 596, 656, 71, 956]\n",
      "\t\t\t\tchambers: \n",
      "\t\t\t\t\t{\n",
      "\t\t\t\t\t1,1: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [468947.0, 495223.0, 933946.0, 523283.0, 912354.0, 544724.0, 917781.0, 570212.0, 579292.0, 572060.0, 600666.0, 456552.0, 610655.0, 642864.0, 636502.0, 647804.0, 661358.0, 702630.0, 458014.0, 800365.0]\n",
      "\t\t\t\t\t\tstd_chamber: [135.0, 142.0, 206.0, 148.0, 205.0, 150.0, 202.0, 157.0, 157.0, 156.0, 160.0, 134.0, 165.0, 169.0, 166.0, 172.0, 172.0, 178.0, 137.0, 192.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,10: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [490584.0, 753449.0, 996616.0, 780848.0, 956578.0, 815317.0, 967917.0, 832076.0, 824184.0, 821190.0, 830193.0, 599113.0, 802926.0, 829600.0, 815588.0, 813541.0, 821437.0, 849516.0, 679183.0, 894883.0]\n",
      "\t\t\t\t\t\tstd_chamber: [143.0, 181.0, 206.0, 187.0, 203.0, 190.0, 208.0, 192.0, 192.0, 193.0, 194.0, 159.0, 193.0, 195.0, 191.0, 191.0, 193.0, 196.0, 171.0, 201.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,11: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [535340.0, 485538.0, 818524.0, 496728.0, 801014.0, 499421.0, 842316.0, 521427.0, 508488.0, 489754.0, 515960.0, 513026.0, 488340.0, 517563.0, 509119.0, 539875.0, 532066.0, 580712.0, 490005.0, 663461.0]\n",
      "\t\t\t\t\t\tstd_chamber: [136.0, 133.0, 174.0, 133.0, 172.0, 134.0, 175.0, 138.0, 135.0, 134.0, 137.0, 134.0, 136.0, 141.0, 136.0, 141.0, 141.0, 149.0, 132.0, 158.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,12: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [470655.0, 721218.0, 1080245.0, 775635.0, 1014988.0, 801196.0, 1028059.0, 835863.0, 835737.0, 829286.0, 836905.0, 570745.0, 833564.0, 854152.0, 836863.0, 852024.0, 862002.0, 883963.0, 647772.0, 944915.0]\n",
      "\t\t\t\t\t\tstd_chamber: [136.0, 172.0, 212.0, 180.0, 205.0, 184.0, 205.0, 188.0, 188.0, 188.0, 189.0, 150.0, 189.0, 191.0, 192.0, 192.0, 192.0, 197.0, 164.0, 200.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,13: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [478166.0, 489205.0, 947494.0, 510785.0, 925715.0, 545181.0, 966055.0, 563899.0, 570733.0, 570826.0, 600189.0, 470683.0, 568195.0, 620881.0, 617719.0, 642148.0, 669995.0, 691957.0, 468226.0, 815515.0]\n",
      "\t\t\t\t\t\tstd_chamber: [285.0, 282.0, 324.0, 281.0, 320.0, 294.0, 321.0, 292.0, 287.0, 292.0, 291.0, 280.0, 286.0, 295.0, 296.0, 294.0, 298.0, 296.0, 278.0, 313.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t...\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t}\n",
      "\t\t\t3: \n",
      "\t\t\t\t{\n",
      "\t\t\t\tconc: 2000.0\n",
      "\t\t\t\ttime_s: [0, 107, 1257, 143, 1557, 179, 1857, 214, 250, 286, 322, 357, 36, 417, 477, 537, 597, 657, 72, 957]\n",
      "\t\t\t\tchambers: \n",
      "\t\t\t\t\t{\n",
      "\t\t\t\t\t1,1: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [5627998.0, 5920694.0, 11383704.0, 6090270.0, 12552552.0, 6207816.0, 13624902.0, 6405748.0, 6614038.0, 6754358.0, 6936485.0, 7094913.0, 5655647.0, 7415492.0, 7796819.0, 8094819.0, 8369920.0, 8615189.0, 5786569.0, 10173032.0]\n",
      "\t\t\t\t\t\tstd_chamber: [417.0, 514.0, 1603.0, 546.0, 1819.0, 584.0, 2014.0, 625.0, 664.0, 698.0, 743.0, 775.0, 447.0, 836.0, 903.0, 966.0, 1018.0, 1079.0, 477.0, 1354.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,10: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [1363446.0, 8447498.0, 22000192.0, 10365329.0, 22147464.0, 11983564.0, 22222185.0, 13361742.0, 14569287.0, 15590652.0, 16573526.0, 17380636.0, 3565965.0, 18594608.0, 19547522.0, 20176072.0, 20646472.0, 20943412.0, 6224505.0, 21898281.0]\n",
      "\t\t\t\t\t\tstd_chamber: [275.0, 1477.0, 3752.0, 1801.0, 3759.0, 2087.0, 3759.0, 2316.0, 2531.0, 2715.0, 2872.0, 3012.0, 638.0, 3215.0, 3374.0, 3476.0, 3547.0, 3604.0, 1089.0, 3743.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,11: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [1503895.0, 1802314.0, 6234549.0, 1955100.0, 7216987.0, 2090102.0, 8109026.0, 2225588.0, 2369030.0, 2491170.0, 2652715.0, 2781230.0, 1541312.0, 3068866.0, 3345926.0, 3568084.0, 3815430.0, 4051724.0, 1678663.0, 5292879.0]\n",
      "\t\t\t\t\t\tstd_chamber: [278.0, 335.0, 1016.0, 357.0, 1166.0, 381.0, 1303.0, 406.0, 430.0, 449.0, 474.0, 494.0, 290.0, 532.0, 576.0, 612.0, 649.0, 688.0, 313.0, 870.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,12: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [1457764.0, 6958205.0, 24322089.0, 8642840.0, 24652175.0, 10088833.0, 24838996.0, 11393315.0, 12571546.0, 13664576.0, 14693028.0, 15598688.0, 3047405.0, 17116710.0, 18418610.0, 19535541.0, 20471010.0, 21219041.0, 5105053.0, 23729057.0]\n",
      "\t\t\t\t\t\tstd_chamber: [289.0, 1234.0, 4179.0, 1526.0, 4221.0, 1777.0, 4231.0, 2005.0, 2213.0, 2408.0, 2580.0, 2739.0, 559.0, 2997.0, 3218.0, 3401.0, 3559.0, 3688.0, 912.0, 4092.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,13: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [1386957.0, 2093055.0, 9623520.0, 2387479.0, 11142535.0, 2683778.0, 12518506.0, 2947950.0, 3201093.0, 3468491.0, 3754681.0, 3999817.0, 1509319.0, 4489910.0, 4909632.0, 5344920.0, 5758692.0, 6144362.0, 1817168.0, 8086768.0]\n",
      "\t\t\t\t\t\tstd_chamber: [376.0, 472.0, 1571.0, 509.0, 1792.0, 554.0, 1996.0, 592.0, 630.0, 666.0, 709.0, 746.0, 393.0, 819.0, 874.0, 934.0, 998.0, 1055.0, 434.0, 1341.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t...\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t}\n",
      "\t\t\t4: \n",
      "\t\t\t\t{\n",
      "\t\t\t\tconc: 250.0\n",
      "\t\t\t\ttime_s: [0, 107, 1258, 143, 1558, 179, 1858, 215, 250, 286, 322, 358, 36, 418, 478, 538, 598, 658, 71, 958]\n",
      "\t\t\t\tchambers: \n",
      "\t\t\t\t\t{\n",
      "\t\t\t\t\t1,1: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [7535584.0, 8382561.0, 14100299.0, 8760094.0, 14987080.0, 9017251.0, 15508256.0, 9292434.0, 9562967.0, 9802961.0, 10015168.0, 10258792.0, 7734090.0, 10656319.0, 11049251.0, 11329217.0, 11528167.0, 11800331.0, 8072487.0, 13333677.0]\n",
      "\t\t\t\t\t\tstd_chamber: [441.0, 483.0, 1002.0, 511.0, 1086.0, 530.0, 1137.0, 550.0, 576.0, 598.0, 619.0, 638.0, 449.0, 675.0, 711.0, 738.0, 763.0, 784.0, 465.0, 927.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,10: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [880995.0, 5370831.0, 11811674.0, 6296887.0, 12157938.0, 6981369.0, 12257941.0, 7521239.0, 7995276.0, 8345707.0, 8723488.0, 8995632.0, 2621311.0, 9471998.0, 9826605.0, 10097197.0, 10342822.0, 10527784.0, 4215896.0, 11501721.0]\n",
      "\t\t\t\t\t\tstd_chamber: [214.0, 578.0, 1158.0, 664.0, 1183.0, 729.0, 1182.0, 785.0, 821.0, 865.0, 893.0, 923.0, 336.0, 965.0, 998.0, 1022.0, 1042.0, 1063.0, 469.0, 1138.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,11: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [775713.0, 1071546.0, 4143507.0, 1204379.0, 4734995.0, 1319881.0, 5129872.0, 1431101.0, 1568418.0, 1651551.0, 1791274.0, 1883931.0, 853886.0, 2093719.0, 2287495.0, 2465715.0, 2632796.0, 2746208.0, 980488.0, 3622744.0]\n",
      "\t\t\t\t\t\tstd_chamber: [153.0, 184.0, 457.0, 198.0, 504.0, 210.0, 543.0, 221.0, 231.0, 242.0, 250.0, 259.0, 162.0, 278.0, 293.0, 310.0, 322.0, 335.0, 176.0, 403.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,12: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [850858.0, 4675163.0, 12579265.0, 5541853.0, 13171457.0, 6241412.0, 13397844.0, 6832114.0, 7367405.0, 7779092.0, 8202876.0, 8534325.0, 2243673.0, 9115483.0, 9607137.0, 9979384.0, 10299599.0, 10591028.0, 3594942.0, 11989015.0]\n",
      "\t\t\t\t\t\tstd_chamber: [157.0, 504.0, 1230.0, 583.0, 1275.0, 657.0, 1293.0, 711.0, 761.0, 803.0, 841.0, 878.0, 275.0, 929.0, 974.0, 1006.0, 1036.0, 1068.0, 402.0, 1179.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,13: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [618191.0, 1413115.0, 6585653.0, 1685668.0, 7410296.0, 1953105.0, 7971561.0, 2184447.0, 2461198.0, 2669471.0, 2875424.0, 3065539.0, 838047.0, 3453987.0, 3761130.0, 4034591.0, 4274868.0, 4526082.0, 1117964.0, 5789835.0]\n",
      "\t\t\t\t\t\tstd_chamber: [273.0, 329.0, 668.0, 340.0, 716.0, 364.0, 760.0, 373.0, 390.0, 403.0, 420.0, 428.0, 289.0, 455.0, 470.0, 492.0, 514.0, 528.0, 311.0, 602.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t...\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t}\n",
      "\t\t\t...\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t}\n",
      "button_quant: \n",
      "\t{\n",
      "\t1,1: \n",
      "\t\t{\n",
      "\t\tsummed_button_Button_Quant: 15041\n",
      "\t\tsummed_button_BGsub_Button_Quant: 7088\n",
      "\t\tstd_button_Button_Quant: 21\n",
      "\t\t}\n",
      "\t1,2: \n",
      "\t\t{\n",
      "\t\tsummed_button_Button_Quant: 21514\n",
      "\t\tsummed_button_BGsub_Button_Quant: 6570\n",
      "\t\tstd_button_Button_Quant: 17\n",
      "\t\t}\n",
      "\t1,3: \n",
      "\t\t{\n",
      "\t\tsummed_button_Button_Quant: 152498\n",
      "\t\tsummed_button_BGsub_Button_Quant: 122704\n",
      "\t\tstd_button_Button_Quant: 163\n",
      "\t\t}\n",
      "\t1,4: \n",
      "\t\t{\n",
      "\t\tsummed_button_Button_Quant: 276149\n",
      "\t\tsummed_button_BGsub_Button_Quant: 239605\n",
      "\t\tstd_button_Button_Quant: 296\n",
      "\t\t}\n",
      "\t1,5: \n",
      "\t\t{\n",
      "\t\tsummed_button_Button_Quant: 1085272\n",
      "\t\tsummed_button_BGsub_Button_Quant: 1051853\n",
      "\t\tstd_button_Button_Quant: 384\n",
      "\t\t}\n",
      "\t...\n",
      "\t}\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(str(db_conn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 4. Standards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each chamber, we've taken values at a set of concentrations. We need to perform a linear regression __for each chamber__ to relate the luminance of each chamber to its substrate concentration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "#N.F. Sometime soon, let's change the HTBAM API so that kinetics/standards are in a unified format. \n",
    "# In both assays, we record information at several concentrations (substrate for kinetics, product for standard)\n",
    "# In standard, we only measure once, while for kinetics, we measure over time. We could have the fluorescence value be a list, of length 1 for standard.\n",
    "\n",
    "def assay_data_to_array(db_obj, run_name):\n",
    "    '''This function takes as input an HTBAM Database object.\n",
    "    For each kinetics run, we have \n",
    "    It returns 3 numpy arrays:\n",
    "    chamber_ids: an array of the chamber ids (in the format '1,1' ... '32,56')\n",
    "        shape: (n_chambers,)\n",
    "    luminance_data: an array of the luminance data for each chamber\n",
    "        shape: (n_time_points, n_chambers, n_assays)\n",
    "    conc_data: an array of the concentration data for each chamber.\n",
    "        shape: (n_assays,)\n",
    "    time_data: an array of the time data for each time point.\n",
    "        shape: (n_time_points, n_assays)\n",
    "    '''\n",
    "    \n",
    "    chamber_idxs = np.array(list(db_obj._json_dict['chamber_metadata'].keys()))\n",
    "    luminance_data = None\n",
    "    time_data = None\n",
    "    conc_data = np.array([])\n",
    "\n",
    "    #Each assay may have recorded a different # of time points.\n",
    "    #First, we'll just check what the max # of time points is:\n",
    "    max_time_points = 0\n",
    "    for assay in db_obj._json_dict[\"runs\"][run_name]['assays'].keys():\n",
    "        current_assay_time_points = len(np.array(db_obj._json_dict[\"runs\"][run_name]['assays'][assay]['time_s']))\n",
    "        if current_assay_time_points > max_time_points:\n",
    "            max_time_points = current_assay_time_points\n",
    "\n",
    "    for assay in db_obj._json_dict[\"runs\"][run_name]['assays'].keys():\n",
    "        current_assay_array = None\n",
    "        #Get luminance data:\n",
    "        for chamber_idx in chamber_idxs:\n",
    "            #collect from DB\n",
    "            current_chamber_array = np.array(db_obj._json_dict[\"runs\"][run_name]['assays'][assay]['chambers'][chamber_idx]['sum_chamber'])\n",
    "            #pad the array with NaNs if there are fewer time points than the max\n",
    "            current_chamber_array = np.pad(current_chamber_array, (0, max_time_points - len(current_chamber_array)), 'constant', constant_values=np.nan)\n",
    "            #add a dimension at the end:\n",
    "            current_chamber_array = np.expand_dims(current_chamber_array, axis=1)\n",
    "\n",
    "            if current_assay_array is None:\n",
    "                current_assay_array = current_chamber_array\n",
    "            else:\n",
    "                current_assay_array = np.concatenate([current_assay_array, current_chamber_array], axis=1)\n",
    "        #add a dimension at the end:\n",
    "        current_assay_array = np.expand_dims(current_assay_array, axis=2)\n",
    "        #add to our dataset\n",
    "        if luminance_data is None:\n",
    "            luminance_data = current_assay_array\n",
    "        else:\n",
    "            luminance_data = np.concatenate([luminance_data, current_assay_array], axis=2)\n",
    "\n",
    "        #Get time data:\n",
    "        #collect from DB\n",
    "        current_time_array = np.array(db_obj._json_dict[\"runs\"][run_name]['assays'][assay]['time_s'])\n",
    "        current_time_array = current_time_array.astype(float) #so we can pad with NaNs\n",
    "        #pad the array with NaNs if there are fewer time points than the max\n",
    "        current_time_array = np.pad(current_time_array, (0, max_time_points - len(current_time_array)), 'constant', constant_values=np.nan)\n",
    "        current_time_array = np.expand_dims(current_time_array, axis=1)\n",
    "        #add to our dataset\n",
    "        if time_data is None:\n",
    "            time_data = current_time_array\n",
    "        else:\n",
    "            time_data = np.concatenate([time_data, current_time_array], axis=1)\n",
    "        \n",
    "        #Get concentration data:\n",
    "        #collect from DB\n",
    "        current_conc = db_obj._json_dict[\"runs\"][run_name]['assays'][assay]['conc']\n",
    "        conc_data = np.append(conc_data, current_conc)\n",
    "    \n",
    "    return chamber_idxs, luminance_data, conc_data, time_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### SANITY CHECK\n",
    "# chamber_idxs, luminance_data, conc_data, time_data = assay_data_to_array(db_conn, 'kinetics_0')\n",
    "# print(conc_data.shape) #expecting (11,)\n",
    "# print(luminance_data.shape) #expecting (20, 1792, 11)\n",
    "# print(time_data.shape) #expecting (20, 11)\n",
    "# print(chamber_idxs.shape) #expecting (1792,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: fix code up to here, now that I unified the formats between kinetics and standard curves. It doesn't like the dimensionality of everything...\n",
    "actually - fixed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1792, 7)\n"
     ]
    }
   ],
   "source": [
    "#since we're just doing a linear fit to all the data here, we don't need the kinetics package.\n",
    "\n",
    "#Here, we collect our data into numpy arrays\n",
    "chamber_idxs, luminance_data, conc_data, _ = assay_data_to_array(db_conn, 'standard_0')\n",
    "\n",
    "#shape should be (n_assays, n_chambers)\n",
    "# 6 x (32*56=1792)\n",
    "print(luminance_data.shape)\n",
    "\n",
    "#Perform linear regression for each chamber:\n",
    "#and store immediately in 'database' object\n",
    "if 'analyses' not in db_conn._json_dict['runs']['standard_0'].keys():\n",
    "    db_conn._json_dict['runs']['standard_0']['analyses'] = {}\n",
    "\n",
    "db_conn._json_dict['runs']['standard_0']['analyses']['linear_regression'] = {'chambers': {}} #initialize the dictionary\n",
    "for i in range(len(chamber_idxs)):\n",
    "    slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(conc_data, luminance_data[:,i])\n",
    "    db_conn._json_dict['runs']['standard_0']['analyses']['linear_regression']['chambers'][chamber_idxs[i]] = {'slope': slope, 'intercept': intercept, 'r_value': r_value, 'r2':r_value**2, 'p_value': p_value, 'std_err': std_err}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "chamber_metadata: \n",
      "\t{\n",
      "\t1,1: \n",
      "\t\t{\n",
      "\t\tid: M_caps_ADK\n",
      "\t\tx_center_chamber: 35.0\n",
      "\t\ty_center_chamber: 51.0\n",
      "\t\tradius_chamber: 35.0\n",
      "\t\txslice: (395, 495)\n",
      "\t\t...\n",
      "\t\t}\n",
      "\t1,2: \n",
      "\t\t{\n",
      "\t\tid: P_syri_ADK\n",
      "\t\tx_center_chamber: 35.0\n",
      "\t\ty_center_chamber: 51.0\n",
      "\t\tradius_chamber: 34.0\n",
      "\t\txslice: (510, 610)\n",
      "\t\t...\n",
      "\t\t}\n",
      "\t1,3: \n",
      "\t\t{\n",
      "\t\tid: L_reut_ADK\n",
      "\t\tx_center_chamber: 37.0\n",
      "\t\ty_center_chamber: 51.0\n",
      "\t\tradius_chamber: 37.0\n",
      "\t\txslice: (626, 726)\n",
      "\t\t...\n",
      "\t\t}\n",
      "\t1,4: \n",
      "\t\t{\n",
      "\t\tid: G_ther_ADK\n",
      "\t\tx_center_chamber: 37.0\n",
      "\t\ty_center_chamber: 49.0\n",
      "\t\tradius_chamber: 36.0\n",
      "\t\txslice: (742, 842)\n",
      "\t\t...\n",
      "\t\t}\n",
      "\t1,5: \n",
      "\t\t{\n",
      "\t\tid: bmADK\n",
      "\t\tx_center_chamber: 35.0\n",
      "\t\ty_center_chamber: 49.0\n",
      "\t\tradius_chamber: 34.0\n",
      "\t\txslice: (858, 958)\n",
      "\t\t...\n",
      "\t\t}\n",
      "\t...\n",
      "\t}\n",
      "runs: \n",
      "\t{\n",
      "\tstandard_0: \n",
      "\t\t{\n",
      "\t\tname: NADPH std curve\n",
      "\t\ttype: NADPH\n",
      "\t\tconc_unit: uM\n",
      "\t\tassays: \n",
      "\t\t\t{\n",
      "\t\t\t0: \n",
      "\t\t\t\t{\n",
      "\t\t\t\tconc: 3.90625\n",
      "\t\t\t\ttime_s: [0]\n",
      "\t\t\t\tchambers: \n",
      "\t\t\t\t\t{\n",
      "\t\t\t\t\t1,1: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [188096.0]\n",
      "\t\t\t\t\t\tstd_chamber: [78.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,10: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [228483.0]\n",
      "\t\t\t\t\t\tstd_chamber: [99.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,11: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [224214.0]\n",
      "\t\t\t\t\t\tstd_chamber: [84.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,12: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [196095.0]\n",
      "\t\t\t\t\t\tstd_chamber: [80.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,13: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [234481.0]\n",
      "\t\t\t\t\t\tstd_chamber: [253.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t...\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t}\n",
      "\t\t\t1: \n",
      "\t\t\t\t{\n",
      "\t\t\t\tconc: 7.8125\n",
      "\t\t\t\ttime_s: [0]\n",
      "\t\t\t\tchambers: \n",
      "\t\t\t\t\t{\n",
      "\t\t\t\t\t1,1: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [240692.0]\n",
      "\t\t\t\t\t\tstd_chamber: [88.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,10: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [259851.0]\n",
      "\t\t\t\t\t\tstd_chamber: [105.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,11: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [267881.0]\n",
      "\t\t\t\t\t\tstd_chamber: [94.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,12: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [229483.0]\n",
      "\t\t\t\t\t\tstd_chamber: [85.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,13: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [266559.0]\n",
      "\t\t\t\t\t\tstd_chamber: [257.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t...\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t}\n",
      "\t\t\t2: \n",
      "\t\t\t\t{\n",
      "\t\t\t\tconc: 15.625\n",
      "\t\t\t\ttime_s: [0]\n",
      "\t\t\t\tchambers: \n",
      "\t\t\t\t\t{\n",
      "\t\t\t\t\t1,1: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [330890.0]\n",
      "\t\t\t\t\t\tstd_chamber: [104.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,10: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [358876.0]\n",
      "\t\t\t\t\t\tstd_chamber: [119.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,11: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [367405.0]\n",
      "\t\t\t\t\t\tstd_chamber: [106.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,12: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [349277.0]\n",
      "\t\t\t\t\t\tstd_chamber: [103.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,13: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [368497.0]\n",
      "\t\t\t\t\t\tstd_chamber: [264.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t...\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t}\n",
      "\t\t\t3: \n",
      "\t\t\t\t{\n",
      "\t\t\t\tconc: 31.25\n",
      "\t\t\t\ttime_s: [0]\n",
      "\t\t\t\tchambers: \n",
      "\t\t\t\t\t{\n",
      "\t\t\t\t\t1,1: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [644967.0]\n",
      "\t\t\t\t\t\tstd_chamber: [141.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,10: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [643179.0]\n",
      "\t\t\t\t\t\tstd_chamber: [147.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,11: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [681549.0]\n",
      "\t\t\t\t\t\tstd_chamber: [138.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,12: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [656808.0]\n",
      "\t\t\t\t\t\tstd_chamber: [134.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,13: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [655309.0]\n",
      "\t\t\t\t\t\tstd_chamber: [272.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t...\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t}\n",
      "\t\t\t4: \n",
      "\t\t\t\t{\n",
      "\t\t\t\tconc: 125.0\n",
      "\t\t\t\ttime_s: [0]\n",
      "\t\t\t\tchambers: \n",
      "\t\t\t\t\t{\n",
      "\t\t\t\t\t1,1: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [2990428.0]\n",
      "\t\t\t\t\t\tstd_chamber: [327.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,10: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [2682125.0]\n",
      "\t\t\t\t\t\tstd_chamber: [289.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,11: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [2997113.0]\n",
      "\t\t\t\t\t\tstd_chamber: [323.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,12: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [3050228.0]\n",
      "\t\t\t\t\t\tstd_chamber: [293.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,13: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [2964056.0]\n",
      "\t\t\t\t\t\tstd_chamber: [399.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t...\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t}\n",
      "\t\t\t...\n",
      "\t\t\t}\n",
      "\t\tanalyses: \n",
      "\t\t\t{\n",
      "\t\t\tlinear_regression: \n",
      "\t\t\t\t{\n",
      "\t\t\t\tchambers: \n",
      "\t\t\t\t\t{\n",
      "\t\t\t\t\t1,1: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tslope: 22733.577962000814\n",
      "\t\t\t\t\t\tintercept: 43975.0999340429\n",
      "\t\t\t\t\t\tr_value: 0.9998427526217066\n",
      "\t\t\t\t\t\tr2: 0.9996855299701513\n",
      "\t\t\t\t\t\tp_value: 5.954918030206768e-10\n",
      "\t\t\t\t\t\t...\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,2: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tslope: 23678.734586242845\n",
      "\t\t\t\t\t\tintercept: 36383.9117678348\n",
      "\t\t\t\t\t\tr_value: 0.9998331684188061\n",
      "\t\t\t\t\t\tr2: 0.9996663646703887\n",
      "\t\t\t\t\t\tp_value: 6.904157486009038e-10\n",
      "\t\t\t\t\t\t...\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,3: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tslope: 25638.041855449883\n",
      "\t\t\t\t\t\tintercept: -12384.234069488011\n",
      "\t\t\t\t\t\tr_value: 0.9998221003666415\n",
      "\t\t\t\t\t\tr2: 0.9996442323815626\n",
      "\t\t\t\t\t\tp_value: 8.106811626021826e-10\n",
      "\t\t\t\t\t\t...\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,4: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tslope: 25345.88627407928\n",
      "\t\t\t\t\t\tintercept: 11886.140901256353\n",
      "\t\t\t\t\t\tr_value: 0.9998277064263551\n",
      "\t\t\t\t\t\tr2: 0.9996554425377857\n",
      "\t\t\t\t\t\tp_value: 7.483184467077394e-10\n",
      "\t\t\t\t\t\t...\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,5: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tslope: 23595.500598880877\n",
      "\t\t\t\t\t\tintercept: 8589.301823365036\n",
      "\t\t\t\t\t\tr_value: 0.9998446234446491\n",
      "\t\t\t\t\t\tr2: 0.9996892710311721\n",
      "\t\t\t\t\t\tp_value: 5.779382148695999e-10\n",
      "\t\t\t\t\t\t...\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t...\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\tkinetics_0: \n",
      "\t\t{\n",
      "\t\tname: ADP kinetics curve\n",
      "\t\ttype: ADP\n",
      "\t\tconc_unit: uM\n",
      "\t\tassays: \n",
      "\t\t\t{\n",
      "\t\t\t0: \n",
      "\t\t\t\t{\n",
      "\t\t\t\tconc: 1000.0\n",
      "\t\t\t\ttime_s: [0, 107, 1257, 143, 1557, 179, 1857, 214, 250, 286, 322, 357, 36, 417, 477, 537, 597, 657, 71, 957]\n",
      "\t\t\t\tchambers: \n",
      "\t\t\t\t\t{\n",
      "\t\t\t\t\t1,1: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [5706550.0, 6111047.0, 11687580.0, 6252476.0, 12771839.0, 6496490.0, 13601648.0, 6560664.0, 6807164.0, 6904110.0, 7100560.0, 7285440.0, 5779893.0, 7742776.0, 8097891.0, 8364556.0, 8657411.0, 8870927.0, 5918860.0, 10368417.0]\n",
      "\t\t\t\t\t\tstd_chamber: [387.0, 478.0, 1495.0, 513.0, 1694.0, 548.0, 1861.0, 583.0, 627.0, 658.0, 696.0, 724.0, 409.0, 796.0, 853.0, 909.0, 969.0, 1015.0, 441.0, 1271.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,10: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [993859.0, 6815357.0, 21599775.0, 8271935.0, 22307698.0, 9475365.0, 22550946.0, 10476613.0, 11408539.0, 12161098.0, 12919157.0, 13566534.0, 2989408.0, 14696183.0, 15726882.0, 16494785.0, 17213104.0, 17816508.0, 5088504.0, 20274702.0]\n",
      "\t\t\t\t\t\tstd_chamber: [219.0, 1210.0, 3669.0, 1461.0, 3772.0, 1669.0, 3801.0, 1843.0, 2000.0, 2136.0, 2265.0, 2370.0, 546.0, 2558.0, 2727.0, 2859.0, 2975.0, 3078.0, 908.0, 3469.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,11: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [1019894.0, 1283020.0, 5306931.0, 1424235.0, 6137206.0, 1558000.0, 6822833.0, 1673322.0, 1811411.0, 1913603.0, 2042143.0, 2168285.0, 1088892.0, 2451438.0, 2723241.0, 2939916.0, 3129633.0, 3308864.0, 1170345.0, 4381145.0]\n",
      "\t\t\t\t\t\tstd_chamber: [211.0, 261.0, 845.0, 283.0, 961.0, 301.0, 1071.0, 322.0, 342.0, 361.0, 378.0, 399.0, 222.0, 438.0, 473.0, 502.0, 534.0, 563.0, 241.0, 714.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,12: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [1018086.0, 5533008.0, 22021641.0, 6805264.0, 23610365.0, 7888695.0, 24491342.0, 8849341.0, 9713049.0, 10436485.0, 11202118.0, 11878670.0, 2472329.0, 13062224.0, 14126802.0, 14966136.0, 15785480.0, 16511326.0, 4099259.0, 19723086.0]\n",
      "\t\t\t\t\t\tstd_chamber: [217.0, 1003.0, 3773.0, 1225.0, 4027.0, 1413.0, 4162.0, 1577.0, 1730.0, 1860.0, 1986.0, 2105.0, 465.0, 2302.0, 2478.0, 2621.0, 2759.0, 2880.0, 748.0, 3411.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,13: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [893434.0, 1562758.0, 8276068.0, 1854220.0, 9517212.0, 2115900.0, 10547386.0, 2365359.0, 2602063.0, 2817998.0, 3057931.0, 3296254.0, 1076345.0, 3749090.0, 4181894.0, 4546259.0, 4891835.0, 5217944.0, 1289226.0, 6855831.0]\n",
      "\t\t\t\t\t\tstd_chamber: [321.0, 409.0, 1345.0, 441.0, 1525.0, 480.0, 1676.0, 514.0, 545.0, 581.0, 613.0, 647.0, 339.0, 705.0, 766.0, 816.0, 866.0, 915.0, 367.0, 1147.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t...\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t}\n",
      "\t\t\t1: \n",
      "\t\t\t\t{\n",
      "\t\t\t\tconc: 125.0\n",
      "\t\t\t\ttime_s: [0, 107, 1258, 143, 1558, 179, 1858, 214, 250, 286, 322, 358, 36, 418, 478, 538, 598, 658, 71, 958]\n",
      "\t\t\t\tchambers: \n",
      "\t\t\t\t\t{\n",
      "\t\t\t\t\t1,1: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [8136071.0, 8779072.0, 12297277.0, 8973313.0, 12711744.0, 9135669.0, 12874143.0, 9337468.0, 9460129.0, 9571357.0, 9656313.0, 9815460.0, 8274315.0, 10101405.0, 10303423.0, 10462064.0, 10687599.0, 10734019.0, 8517578.0, 11716124.0]\n",
      "\t\t\t\t\t\tstd_chamber: [487.0, 511.0, 755.0, 519.0, 795.0, 531.0, 801.0, 539.0, 552.0, 565.0, 576.0, 584.0, 488.0, 604.0, 615.0, 635.0, 649.0, 658.0, 498.0, 715.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,10: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [625410.0, 3474955.0, 6217674.0, 3918941.0, 6377513.0, 4242168.0, 6363578.0, 4512960.0, 4710216.0, 4847984.0, 4966483.0, 5048604.0, 1780525.0, 5245305.0, 5388851.0, 5491937.0, 5573753.0, 5632528.0, 2794202.0, 6016738.0]\n",
      "\t\t\t\t\t\tstd_chamber: [195.0, 418.0, 639.0, 456.0, 647.0, 484.0, 643.0, 510.0, 528.0, 541.0, 551.0, 562.0, 277.0, 578.0, 588.0, 597.0, 601.0, 607.0, 353.0, 629.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,11: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [540378.0, 738863.0, 2930814.0, 807846.0, 3332516.0, 866794.0, 3533592.0, 955709.0, 1045780.0, 1095217.0, 1154148.0, 1224701.0, 592045.0, 1363423.0, 1517568.0, 1633090.0, 1759191.0, 1836781.0, 680949.0, 2467240.0]\n",
      "\t\t\t\t\t\tstd_chamber: [132.0, 156.0, 345.0, 165.0, 376.0, 170.0, 396.0, 181.0, 191.0, 195.0, 199.0, 207.0, 140.0, 221.0, 236.0, 244.0, 254.0, 261.0, 152.0, 310.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,12: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [567603.0, 3128404.0, 6835637.0, 3622077.0, 7062621.0, 4005722.0, 7068715.0, 4325448.0, 4580633.0, 4786534.0, 4959712.0, 5110547.0, 1525622.0, 5365631.0, 5581630.0, 5739273.0, 5883106.0, 5966593.0, 2458335.0, 6557399.0]\n",
      "\t\t\t\t\t\tstd_chamber: [137.0, 369.0, 685.0, 416.0, 695.0, 455.0, 701.0, 485.0, 509.0, 529.0, 543.0, 561.0, 225.0, 585.0, 599.0, 614.0, 626.0, 631.0, 305.0, 669.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,13: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [414467.0, 950454.0, 4466705.0, 1143795.0, 4952392.0, 1311376.0, 5244840.0, 1483921.0, 1649943.0, 1766141.0, 1906750.0, 2032047.0, 562480.0, 2279292.0, 2516475.0, 2703785.0, 2876810.0, 3023237.0, 763219.0, 3857929.0]\n",
      "\t\t\t\t\t\tstd_chamber: [257.0, 296.0, 515.0, 311.0, 538.0, 330.0, 561.0, 334.0, 347.0, 354.0, 364.0, 372.0, 273.0, 380.0, 401.0, 416.0, 423.0, 428.0, 286.0, 481.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t...\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t}\n",
      "\t\t\t2: \n",
      "\t\t\t\t{\n",
      "\t\t\t\tconc: 15.625\n",
      "\t\t\t\ttime_s: [0, 107, 1256, 142, 1556, 178, 1856, 214, 250, 285, 321, 35, 356, 416, 476, 536, 596, 656, 71, 956]\n",
      "\t\t\t\tchambers: \n",
      "\t\t\t\t\t{\n",
      "\t\t\t\t\t1,1: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [468947.0, 495223.0, 933946.0, 523283.0, 912354.0, 544724.0, 917781.0, 570212.0, 579292.0, 572060.0, 600666.0, 456552.0, 610655.0, 642864.0, 636502.0, 647804.0, 661358.0, 702630.0, 458014.0, 800365.0]\n",
      "\t\t\t\t\t\tstd_chamber: [135.0, 142.0, 206.0, 148.0, 205.0, 150.0, 202.0, 157.0, 157.0, 156.0, 160.0, 134.0, 165.0, 169.0, 166.0, 172.0, 172.0, 178.0, 137.0, 192.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,10: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [490584.0, 753449.0, 996616.0, 780848.0, 956578.0, 815317.0, 967917.0, 832076.0, 824184.0, 821190.0, 830193.0, 599113.0, 802926.0, 829600.0, 815588.0, 813541.0, 821437.0, 849516.0, 679183.0, 894883.0]\n",
      "\t\t\t\t\t\tstd_chamber: [143.0, 181.0, 206.0, 187.0, 203.0, 190.0, 208.0, 192.0, 192.0, 193.0, 194.0, 159.0, 193.0, 195.0, 191.0, 191.0, 193.0, 196.0, 171.0, 201.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,11: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [535340.0, 485538.0, 818524.0, 496728.0, 801014.0, 499421.0, 842316.0, 521427.0, 508488.0, 489754.0, 515960.0, 513026.0, 488340.0, 517563.0, 509119.0, 539875.0, 532066.0, 580712.0, 490005.0, 663461.0]\n",
      "\t\t\t\t\t\tstd_chamber: [136.0, 133.0, 174.0, 133.0, 172.0, 134.0, 175.0, 138.0, 135.0, 134.0, 137.0, 134.0, 136.0, 141.0, 136.0, 141.0, 141.0, 149.0, 132.0, 158.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,12: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [470655.0, 721218.0, 1080245.0, 775635.0, 1014988.0, 801196.0, 1028059.0, 835863.0, 835737.0, 829286.0, 836905.0, 570745.0, 833564.0, 854152.0, 836863.0, 852024.0, 862002.0, 883963.0, 647772.0, 944915.0]\n",
      "\t\t\t\t\t\tstd_chamber: [136.0, 172.0, 212.0, 180.0, 205.0, 184.0, 205.0, 188.0, 188.0, 188.0, 189.0, 150.0, 189.0, 191.0, 192.0, 192.0, 192.0, 197.0, 164.0, 200.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,13: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [478166.0, 489205.0, 947494.0, 510785.0, 925715.0, 545181.0, 966055.0, 563899.0, 570733.0, 570826.0, 600189.0, 470683.0, 568195.0, 620881.0, 617719.0, 642148.0, 669995.0, 691957.0, 468226.0, 815515.0]\n",
      "\t\t\t\t\t\tstd_chamber: [285.0, 282.0, 324.0, 281.0, 320.0, 294.0, 321.0, 292.0, 287.0, 292.0, 291.0, 280.0, 286.0, 295.0, 296.0, 294.0, 298.0, 296.0, 278.0, 313.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t...\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t}\n",
      "\t\t\t3: \n",
      "\t\t\t\t{\n",
      "\t\t\t\tconc: 2000.0\n",
      "\t\t\t\ttime_s: [0, 107, 1257, 143, 1557, 179, 1857, 214, 250, 286, 322, 357, 36, 417, 477, 537, 597, 657, 72, 957]\n",
      "\t\t\t\tchambers: \n",
      "\t\t\t\t\t{\n",
      "\t\t\t\t\t1,1: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [5627998.0, 5920694.0, 11383704.0, 6090270.0, 12552552.0, 6207816.0, 13624902.0, 6405748.0, 6614038.0, 6754358.0, 6936485.0, 7094913.0, 5655647.0, 7415492.0, 7796819.0, 8094819.0, 8369920.0, 8615189.0, 5786569.0, 10173032.0]\n",
      "\t\t\t\t\t\tstd_chamber: [417.0, 514.0, 1603.0, 546.0, 1819.0, 584.0, 2014.0, 625.0, 664.0, 698.0, 743.0, 775.0, 447.0, 836.0, 903.0, 966.0, 1018.0, 1079.0, 477.0, 1354.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,10: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [1363446.0, 8447498.0, 22000192.0, 10365329.0, 22147464.0, 11983564.0, 22222185.0, 13361742.0, 14569287.0, 15590652.0, 16573526.0, 17380636.0, 3565965.0, 18594608.0, 19547522.0, 20176072.0, 20646472.0, 20943412.0, 6224505.0, 21898281.0]\n",
      "\t\t\t\t\t\tstd_chamber: [275.0, 1477.0, 3752.0, 1801.0, 3759.0, 2087.0, 3759.0, 2316.0, 2531.0, 2715.0, 2872.0, 3012.0, 638.0, 3215.0, 3374.0, 3476.0, 3547.0, 3604.0, 1089.0, 3743.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,11: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [1503895.0, 1802314.0, 6234549.0, 1955100.0, 7216987.0, 2090102.0, 8109026.0, 2225588.0, 2369030.0, 2491170.0, 2652715.0, 2781230.0, 1541312.0, 3068866.0, 3345926.0, 3568084.0, 3815430.0, 4051724.0, 1678663.0, 5292879.0]\n",
      "\t\t\t\t\t\tstd_chamber: [278.0, 335.0, 1016.0, 357.0, 1166.0, 381.0, 1303.0, 406.0, 430.0, 449.0, 474.0, 494.0, 290.0, 532.0, 576.0, 612.0, 649.0, 688.0, 313.0, 870.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,12: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [1457764.0, 6958205.0, 24322089.0, 8642840.0, 24652175.0, 10088833.0, 24838996.0, 11393315.0, 12571546.0, 13664576.0, 14693028.0, 15598688.0, 3047405.0, 17116710.0, 18418610.0, 19535541.0, 20471010.0, 21219041.0, 5105053.0, 23729057.0]\n",
      "\t\t\t\t\t\tstd_chamber: [289.0, 1234.0, 4179.0, 1526.0, 4221.0, 1777.0, 4231.0, 2005.0, 2213.0, 2408.0, 2580.0, 2739.0, 559.0, 2997.0, 3218.0, 3401.0, 3559.0, 3688.0, 912.0, 4092.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,13: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [1386957.0, 2093055.0, 9623520.0, 2387479.0, 11142535.0, 2683778.0, 12518506.0, 2947950.0, 3201093.0, 3468491.0, 3754681.0, 3999817.0, 1509319.0, 4489910.0, 4909632.0, 5344920.0, 5758692.0, 6144362.0, 1817168.0, 8086768.0]\n",
      "\t\t\t\t\t\tstd_chamber: [376.0, 472.0, 1571.0, 509.0, 1792.0, 554.0, 1996.0, 592.0, 630.0, 666.0, 709.0, 746.0, 393.0, 819.0, 874.0, 934.0, 998.0, 1055.0, 434.0, 1341.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t...\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t}\n",
      "\t\t\t4: \n",
      "\t\t\t\t{\n",
      "\t\t\t\tconc: 250.0\n",
      "\t\t\t\ttime_s: [0, 107, 1258, 143, 1558, 179, 1858, 215, 250, 286, 322, 358, 36, 418, 478, 538, 598, 658, 71, 958]\n",
      "\t\t\t\tchambers: \n",
      "\t\t\t\t\t{\n",
      "\t\t\t\t\t1,1: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [7535584.0, 8382561.0, 14100299.0, 8760094.0, 14987080.0, 9017251.0, 15508256.0, 9292434.0, 9562967.0, 9802961.0, 10015168.0, 10258792.0, 7734090.0, 10656319.0, 11049251.0, 11329217.0, 11528167.0, 11800331.0, 8072487.0, 13333677.0]\n",
      "\t\t\t\t\t\tstd_chamber: [441.0, 483.0, 1002.0, 511.0, 1086.0, 530.0, 1137.0, 550.0, 576.0, 598.0, 619.0, 638.0, 449.0, 675.0, 711.0, 738.0, 763.0, 784.0, 465.0, 927.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,10: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [880995.0, 5370831.0, 11811674.0, 6296887.0, 12157938.0, 6981369.0, 12257941.0, 7521239.0, 7995276.0, 8345707.0, 8723488.0, 8995632.0, 2621311.0, 9471998.0, 9826605.0, 10097197.0, 10342822.0, 10527784.0, 4215896.0, 11501721.0]\n",
      "\t\t\t\t\t\tstd_chamber: [214.0, 578.0, 1158.0, 664.0, 1183.0, 729.0, 1182.0, 785.0, 821.0, 865.0, 893.0, 923.0, 336.0, 965.0, 998.0, 1022.0, 1042.0, 1063.0, 469.0, 1138.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,11: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [775713.0, 1071546.0, 4143507.0, 1204379.0, 4734995.0, 1319881.0, 5129872.0, 1431101.0, 1568418.0, 1651551.0, 1791274.0, 1883931.0, 853886.0, 2093719.0, 2287495.0, 2465715.0, 2632796.0, 2746208.0, 980488.0, 3622744.0]\n",
      "\t\t\t\t\t\tstd_chamber: [153.0, 184.0, 457.0, 198.0, 504.0, 210.0, 543.0, 221.0, 231.0, 242.0, 250.0, 259.0, 162.0, 278.0, 293.0, 310.0, 322.0, 335.0, 176.0, 403.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,12: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [850858.0, 4675163.0, 12579265.0, 5541853.0, 13171457.0, 6241412.0, 13397844.0, 6832114.0, 7367405.0, 7779092.0, 8202876.0, 8534325.0, 2243673.0, 9115483.0, 9607137.0, 9979384.0, 10299599.0, 10591028.0, 3594942.0, 11989015.0]\n",
      "\t\t\t\t\t\tstd_chamber: [157.0, 504.0, 1230.0, 583.0, 1275.0, 657.0, 1293.0, 711.0, 761.0, 803.0, 841.0, 878.0, 275.0, 929.0, 974.0, 1006.0, 1036.0, 1068.0, 402.0, 1179.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t1,13: \n",
      "\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\tsum_chamber: [618191.0, 1413115.0, 6585653.0, 1685668.0, 7410296.0, 1953105.0, 7971561.0, 2184447.0, 2461198.0, 2669471.0, 2875424.0, 3065539.0, 838047.0, 3453987.0, 3761130.0, 4034591.0, 4274868.0, 4526082.0, 1117964.0, 5789835.0]\n",
      "\t\t\t\t\t\tstd_chamber: [273.0, 329.0, 668.0, 340.0, 716.0, 364.0, 760.0, 373.0, 390.0, 403.0, 420.0, 428.0, 289.0, 455.0, 470.0, 492.0, 514.0, 528.0, 311.0, 602.0]\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t...\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t}\n",
      "\t\t\t...\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t}\n",
      "button_quant: \n",
      "\t{\n",
      "\t1,1: \n",
      "\t\t{\n",
      "\t\tsummed_button_Button_Quant: 15041\n",
      "\t\tsummed_button_BGsub_Button_Quant: 7088\n",
      "\t\tstd_button_Button_Quant: 21\n",
      "\t\t}\n",
      "\t1,2: \n",
      "\t\t{\n",
      "\t\tsummed_button_Button_Quant: 21514\n",
      "\t\tsummed_button_BGsub_Button_Quant: 6570\n",
      "\t\tstd_button_Button_Quant: 17\n",
      "\t\t}\n",
      "\t1,3: \n",
      "\t\t{\n",
      "\t\tsummed_button_Button_Quant: 152498\n",
      "\t\tsummed_button_BGsub_Button_Quant: 122704\n",
      "\t\tstd_button_Button_Quant: 163\n",
      "\t\t}\n",
      "\t1,4: \n",
      "\t\t{\n",
      "\t\tsummed_button_Button_Quant: 276149\n",
      "\t\tsummed_button_BGsub_Button_Quant: 239605\n",
      "\t\tstd_button_Button_Quant: 296\n",
      "\t\t}\n",
      "\t1,5: \n",
      "\t\t{\n",
      "\t\tsummed_button_Button_Quant: 1085272\n",
      "\t\tsummed_button_BGsub_Button_Quant: 1051853\n",
      "\t\tstd_button_Button_Quant: 384\n",
      "\t\t}\n",
      "\t...\n",
      "\t}\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(db_conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(chamber_idxs)):\n",
    "#     #slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(conc_data[:,i], luminance_data[:,i])\n",
    "#     print(db_conn._json_dict['runs']['standard_0']['analyses']['linear_regression']['chambers'][chamber_idxs[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_curves_with_var(db_obj, run_name, analysis_name, analysis_var, title=None):\n",
    "    ''' This function creates a Dash visualization of a chip, based on a certain Run (run_name)\n",
    "        Each well will be colored by a variable that is specified by analysis_var, from the analysis specified by analysis_name.\n",
    "        For example, to color the chip based on the slope of the linear regression, you would set analysis_var='slope' and analysis_name='linear_regression'\n",
    "    '''\n",
    "    from dash import Dash, dcc, html, Input, Output, no_update\n",
    "    import plotly.graph_objs as go\n",
    "    import base64\n",
    "    import tempfile\n",
    "\n",
    "    #get chamber ids:\n",
    "    chamber_idxs, luminance_data, conc_data, time_data = assay_data_to_array(db_conn, 'standard_0')\n",
    "    chamber_ids = np.array([db_obj._json_dict['chamber_metadata'][chamber_idx]['id'] for chamber_idx in chamber_idxs])\n",
    "    \n",
    "    #get slope from the analysis:\n",
    "    slope = np.array([db_obj._json_dict['runs'][run_name]['analyses'][analysis_name]['chambers'][chamber_idx]['slope'] for chamber_idx in chamber_idxs])\n",
    "    intercept = np.array([db_obj._json_dict['runs'][run_name]['analyses'][analysis_name]['chambers'][chamber_idx]['intercept'] for chamber_idx in chamber_idxs])\n",
    "    #get our special var, specified by 'analysis_var', to be used for coloring:\n",
    "    coloring_var = np.array([db_obj._json_dict['runs'][run_name]['analyses'][analysis_name]['chambers'][chamber_idx][analysis_var] for chamber_idx in chamber_idxs])\n",
    "\n",
    "    # Make the image array\n",
    "    #N.B. eventually, store width/height in DB and reference!\n",
    "    img_array = np.zeros([56,32])\n",
    "\n",
    "    for i, chamber_id in enumerate(chamber_idxs):\n",
    "        x = int(chamber_id.split(',')[0])\n",
    "        y = int(chamber_id.split(',')[1])\n",
    "        img_array[y-1,x-1] = coloring_var[i]\n",
    "    \n",
    "    #generate title\n",
    "    if title is None:\n",
    "        title = analysis_var + ' by chamber, for ' + run_name\n",
    "\n",
    "    #Create the figure\n",
    "    layout = go.Layout()\n",
    "    fig = go.Figure(layout=layout, data=go.Heatmap(z=img_array, colorscale='Viridis'))\n",
    "    fig.update_layout(title=title, \n",
    "                        yaxis=dict(scaleanchor=\"x\", scaleratio=1, autorange='reversed'), \n",
    "                        xaxis=dict(scaleratio=1),\n",
    "                        plot_bgcolor='rgba(0,0,0,0)',\n",
    "                        width=600, height=600,\n",
    "                        hovermode='x')\n",
    "    fig.update_xaxes(showticklabels=False)\n",
    "    fig.update_yaxes(showticklabels=False)\n",
    "\n",
    "    #create dash app:\n",
    "    app = Dash(__name__)\n",
    "    app.layout = html.Div([\n",
    "        dcc.Graph(id=\"graph\", figure=fig, clear_on_unhover=True),\n",
    "        dcc.Tooltip(id=\"graph-tooltip\"),\n",
    "    ])\n",
    "\n",
    "    @app.callback(\n",
    "        Output(\"graph-tooltip\", \"show\"),\n",
    "        Output(\"graph-tooltip\", \"bbox\"),\n",
    "        Output(\"graph-tooltip\", \"children\"),\n",
    "        Input(\"graph\", \"hoverData\"),\n",
    "    )\n",
    "    def display_hover(hoverData):\n",
    "        if hoverData is None:\n",
    "            return False, no_update, no_update\n",
    "\n",
    "        # demo only shows the first point, but other points may also be available\n",
    "        pt = hoverData[\"points\"][0]\n",
    "        bbox = pt[\"bbox\"]\n",
    "\n",
    "        #get the data for the point:\n",
    "        \n",
    "        data_name = str(pt['x']+1) + ',' + str(pt['y']+1)\n",
    "        data_id = list(chamber_idxs).index(data_name)\n",
    "        x_data = conc_data[:,data_id]\n",
    "        y_data = luminance_data[:,data_id]\n",
    "        m = slope[data_id]\n",
    "        b = intercept[data_id]\n",
    "        chamber_name = chamber_ids[pt['x']+pt['y']*32]\n",
    "\n",
    "        #make a simple matplotlib plot\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.scatter(x_data, y_data)\n",
    "        if not (np.isnan(m) or np.isnan(b)):\n",
    "            #return False, no_update, no_update\n",
    "            ax.plot(x_data, m*np.array(x_data) + b)\n",
    "        #reduce whitespace on margins of graph:\n",
    "        fig.subplots_adjust(left=0.1, bottom=0.1, right=0.9, top=0.9, wspace=0, hspace=0)\n",
    "        #save the figure as a temp file:\n",
    "        tempfile_name = tempfile.NamedTemporaryFile().name+'.png'\n",
    "        plt.savefig(tempfile_name)\n",
    "        plt.close()\n",
    "\n",
    "        # #read in temp file as base64 encoded string:\n",
    "        with open(tempfile_name, \"rb\") as image_file:\n",
    "            img_src = \"data:image/png;base64,\" + str(base64.b64encode(image_file.read()).decode(\"utf-8\"))\n",
    "        \n",
    "        children = [\n",
    "            html.Div(children=[\n",
    "                #no space after header:\n",
    "                html.H3('{},{}:  {}'.format(pt['x'], pt['y'], chamber_name), style={\"color\": 'black', \"fontFamily\":\"Arial\", \"textAlign\": \"center\", \"marginBottom\": \"0px\"}),\n",
    "                #add the image with reduced whitespace:\n",
    "                html.Img(src=img_src, style={\"width\": \"100%\"}),\n",
    "            ],\n",
    "            style={'width': '400px', 'white-space': 'none'})\n",
    "        ]\n",
    "\n",
    "        return True, bbox, children\n",
    "    \n",
    "    app.run_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fe01bf55d20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_curves_with_var(db_conn, 'standard_0', 'linear_regression', 'r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following is old code, which I have here to reference as I fix the rest:\n",
    "\n",
    "# #takes a DataFrame df as input and performs a linear regression analysis on the data in the DataFrame\n",
    "# def fit_standard_linear(df):\n",
    "    \n",
    "#     # Make a copy of the input DataFrame and sort it based on 'concentration_uM' column.\n",
    "#     dfcopy = df.copy().sort_values('concentration_uM')\n",
    "    \n",
    "#     # Perform linear regression on the 'concentration_uM' and 'sum_chamber' columns of the DataFrame.\n",
    "#     slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(df.concentration_uM, df.sum_chamber)\n",
    "\n",
    "#     # Create a new pandas Series to store the results of the linear regression analysis.\n",
    "#     # Define specific index names to store each result.\n",
    "#     fitted_series = pd.Series(data = [df.iloc[0].id,\n",
    "#                       dfcopy.iloc[0].x, dfcopy.iloc[0].y, \n",
    "#                       dfcopy.concentration_uM.values.tolist(), \n",
    "#                       dfcopy.sum_chamber.values.tolist(),\n",
    "#                       dfcopy.std_chamber.values.tolist(),\n",
    "#                      slope, intercept, r_value**2, p_value, std_err],\n",
    "#               index = ['id', 'x', 'y', 'std_concs', 'std_summed_intensity', 'std_stddev_intensity', 'std_slope', \n",
    "#                        'std_intercept', 'std_r2', 'std_pvalue', 'std_stderr'])\n",
    "#     return fitted_series\n",
    "\n",
    "\n",
    "# # Fit linear regression by chamber\n",
    "# # Group the DataFrame 'standard_data' by the values in the 'indices' (i.e. chamber coord) column and apply the 'fit_standard_linear' function to each group. \n",
    "# # The result is a Series containing the output of linear regression analysis for each chamber\n",
    "\n",
    "# fitted_standards_filtered = standard_data.groupby('indices').apply(fit_standard_linear)\n",
    "\n",
    "# # Add additional descriptors\n",
    "# fitted_standards_filtered['std_slope_units'] = 'RFU/uM'\n",
    "# fitted_standards_filtered['substrate_name'] = 'ADP'\n",
    "# fitted_standards_filtered['experimental_day'] = '20230628'\n",
    "# fitted_standards_filtered['setup'] = '1'\n",
    "# fitted_standards_filtered['device'] = 'd2'\n",
    "# fitted_standards_filtered['assay_type'] = 'NADPH'\n",
    "# fitted_standards_filtered['position'] = [(int(r['y']),int(r['x'])) for i,r in fitted_standards_filtered.iterrows()]\n",
    "\n",
    "# fitted_standards_filtered = fitted_standards_filtered.sort_values(by = 'position')\n",
    "# fitted_standards_filtered.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NF: completely replace\n",
    "# Is this useful? I don't think so.\n",
    "# plot how standard curve parameters vary based on location in the device\n",
    "\n",
    "# def plot_std_curve_parameters(df, filename = 'standard_curve_parameters'):\n",
    "#     # plot how slope and r2 vary accross the chip\n",
    "#     fig, ax = plt.subplots(nrows=2, ncols=3, figsize=(20, 10))\n",
    "#     plt.xticks(fontsize=6)\n",
    "#     plt.yticks(fontsize=6)\n",
    "    \n",
    "#     # Flatten the axes array for easy indexing\n",
    "#     ax = ax.flatten()\n",
    "    \n",
    "#     ax[0].scatter(df['x'], df['std_r2'], color = 'b')\n",
    "#     ax[0].set_xlabel('x-index', fontsize = 12)\n",
    "#     ax[0].set_ylabel('r2', fontsize = 12)\n",
    "    \n",
    "#     ax[1].scatter(df['y'], df['std_r2'], color = 'b')\n",
    "#     ax[1].set_xlabel('y-index', fontsize = 12)\n",
    "#     ax[1].set_ylabel('r2', fontsize = 12)\n",
    "    \n",
    "#     ax[2].hist(df['std_r2'])\n",
    "#     ax[2].set_xlabel('r2', fontsize = 12)\n",
    "#     ax[2].set_ylabel('count', fontsize = 12)\n",
    "    \n",
    "#     ax[3].scatter(df['x'], df['std_slope'], color = 'b')\n",
    "#     ax[3].set_xlabel('x-index', fontsize = 12)\n",
    "#     ax[3].set_ylabel('slope', fontsize = 12)\n",
    "    \n",
    "#     ax[4].scatter(df['y'], df['std_slope'], color = 'b')\n",
    "#     ax[4].set_xlabel('y-index', fontsize = 12)\n",
    "#     ax[4].set_ylabel('slope', fontsize = 12)\n",
    "    \n",
    "#     ax[5].hist(df['std_slope'])\n",
    "#     ax[5].set_xlabel('slope', fontsize = 12)\n",
    "#     ax[5].set_ylabel('count', fontsize = 12)\n",
    "    \n",
    "#     plt.tight_layout()\n",
    "#     plt.rcParams['pdf.fonttype'] = 42\n",
    "#     plt.savefig('{}.pdf'.format(filename), format='pdf')\n",
    "    \n",
    "\n",
    "# plot_std_curve_parameters(fitted_standards_filtered, 'NADPH_standard_curve_parameters')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save final filtered standard curve\n",
    "# fitted_standards_filtered.to_csv(new_root+'/2_fitted_standards_filtered.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Fit initial rates from processed kinetic data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean and merge dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #NF: Need to completely rework how we track variables like substrate, concentrations with experimental data.\n",
    "\n",
    "# # define the substrate concentrations and corresponding file descriptions used in the kinetics experiment\n",
    "# # concentrations = [15.625,\n",
    "# #                  31.125,\n",
    "# #                  62.5,\n",
    "# #                  125,\n",
    "# #                  250,\n",
    "# #                  500,\n",
    "# #                  1000,\n",
    "# #                  2000,\n",
    "# #                  4000,\n",
    "# #                  8000,\n",
    "# #                  16000]\n",
    "\n",
    "# # kinetic_descriptions = ['7_8125uM_ADP',\n",
    "# #                         '15_625uM_ADP',\n",
    "# #                         '31_125uM_ADP',\n",
    "# #                         '62.5uM_ADP',\n",
    "# #                         '125uM_ADP',\n",
    "# #                         '250uM_ADP',\n",
    "# #                         '500uM_ADP',\n",
    "# #                         '1000uMADP',\n",
    "# #                         '2000uM_ADP',\n",
    "# #                         '4000uM_ADP',\n",
    "# #                         '8000uM_ADP']\n",
    "                        \n",
    "# substrate_conc_mapper = {d:c for (d,c) in zip(kinetic_descriptions, concentrations)}\n",
    "\n",
    "# # for filtering if a particular susbtrate concentration should not be processed\n",
    "# # mmfit_mask_mapper = {'7_8125uM_ADP': True, \n",
    "# #                      '15_625uM_ADP': True, \n",
    "# #                      '31_125uM_ADP': True, \n",
    "# #                      '62.5uM_ADP': True, \n",
    "# #                      '125uM_ADP': True, \n",
    "# #                      '250uM_ADP': True, \n",
    "# #                      '500uM_ADP': True,\n",
    "# #                      '1000uMADP': True,\n",
    "# #                      '2000uM_ADP': True,\n",
    "# #                      '4000uM_ADP': True,\n",
    "# #                      '8000uM_ADP': True}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #NF where are we generating this? we need to specify the file path.\n",
    "\n",
    "# #read in the kinetic data (chamber intensities vs time) processed above\n",
    "# full_kinetic_data = pd.read_csv(root+'/kinetics/d2_TitrationSeries_Analysis.csv.bz2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #NF: Can we arrange our data such that we don't need to change format halfway through?\n",
    "\n",
    "# # takes a tidy DataFrame of chamber intensity values and timepoint as input and compresses these values \n",
    "# # into a single row by returning a series where intensity values and timepoints are each a list\n",
    "\n",
    "# def squeeze_kinetics(df):\n",
    "#     # Create a copy of the input DataFrame and sort it based on the 'time_s' column.\n",
    "#     dfcopy = df.copy().sort_values('time_s')\n",
    "\n",
    "#     # Extract relevant data for the first row of the sorted DataFrame.\n",
    "#     # These values are assumed to be the same for all rows in the group.\n",
    "#     chamber_id = dfcopy.iloc[0]['id']\n",
    "#     substrate_conc = dfcopy.iloc[0]['substrate_conc']\n",
    "#     mm_tofit_mask = dfcopy.iloc[0]['mm_tofit_mask']\n",
    "\n",
    "#     # Extract specific column data as lists.\n",
    "#     median_chamber = dfcopy.median_chamber.values.tolist()\n",
    "#     sum_chamber = dfcopy.sum_chamber.values.tolist()\n",
    "#     std_chamber = dfcopy.std_chamber.values.tolist()\n",
    "#     button_quant_raw = dfcopy.summed_button_Button_Quant.values.tolist()\n",
    "#     button_quant_bgsub = dfcopy.summed_button_BGsub_Button_Quant.values.tolist()\n",
    "#     times = dfcopy.time_s.values.tolist()\n",
    "    \n",
    "#     # Create a new pandas Series to store the extracted data.\n",
    "#     squeezed_series = pd.Series(data = [chamber_id, mm_tofit_mask, substrate_conc, times, median_chamber, \n",
    "#                                         sum_chamber, std_chamber, button_quant_raw, button_quant_bgsub],\n",
    "#                                index = ['id', 'mm_tofit_mask','substrate_conc', 'time_s', 'chamber_median', \n",
    "#                                         'chamber_sum', 'chamber_stddev', 'button_sum', 'button_sum_bgsub'])\n",
    "#     return squeezed_series\n",
    "\n",
    "# #NF: We do a similar thing above for standard curve, but slightly different. Must standardize (or remove)\n",
    "\n",
    "# # Add additional descriptors\n",
    "# full_kinetic_data['indices'] = full_kinetic_data.x.astype('str') + ',' + full_kinetic_data.y.astype('str')\n",
    "# full_kinetic_data['substrate_conc'] = full_kinetic_data.series_index.map(substrate_conc_mapper)\n",
    "# full_kinetic_data['mm_tofit_mask'] = full_kinetic_data.series_index.map(mmfit_mask_mapper)\n",
    "\n",
    "# # Create 'untidy' data by chamber position (\"indices\") and substrate concentration (\"series_index\")\n",
    "# squeezed_kinetic_data = full_kinetic_data.groupby(['indices', 'series_index']).apply(squeeze_kinetics).reset_index().set_index('indices')\n",
    "# squeezed_kinetic_data.head(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will keep 1761 out of 1792 chambers.\n"
     ]
    }
   ],
   "source": [
    "#Here, we determine which chambers we want to discard.\n",
    "#We do this by choosing a Pearson r^2 value threshold, and discarding any chambers that have a lower r^2 value than that threshold.\n",
    "r2_threshold = 0.98\n",
    "\n",
    "chamber_idxs = np.array(list(db_conn._json_dict['chamber_metadata'].keys()))\n",
    "r2_values = np.array([db_conn._json_dict['runs']['standard_0']['analyses']['linear_regression']['chambers'][chamber_idx]['r2'] for chamber_idx in chamber_idxs])\n",
    "\n",
    "#find the indices of the chambers that we want to keep:\n",
    "chamber_idxs_to_keep = chamber_idxs[r2_values > r2_threshold]\n",
    "\n",
    "print('We will keep {} out of {} chambers.'.format(len(chamber_idxs_to_keep), len(chamber_idxs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fe022df0250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#NF: I should abstract this, since I'm using the same code to plot the data. Only difference is which data / what representation.\n",
    "\n",
    "#Sanity check by plotting:\n",
    "def plot_chip_by_idx(chamber_idx_to_keep, title=None):\n",
    "    ''' This function creates a Dash visualization of a chip, based on a certain Run (run_name)\n",
    "        Each well will be colored by a variable that is specified by analysis_var, from the analysis specified by analysis_name.\n",
    "        For example, to color the chip based on the slope of the linear regression, you would set analysis_var='slope' and analysis_name='linear_regression'\n",
    "    '''\n",
    "    from dash import Dash, dcc, html, Input, Output, no_update\n",
    "    import plotly.graph_objs as go\n",
    "    import base64\n",
    "    import tempfile\n",
    "\n",
    "    # Make the image array\n",
    "    #N.B. eventually, store width/height in DB and reference!\n",
    "    img_array = np.zeros([56,32])\n",
    "\n",
    "    for i, chamber_id in enumerate(chamber_idx_to_keep):\n",
    "        x = int(chamber_id.split(',')[0])\n",
    "        y = int(chamber_id.split(',')[1])\n",
    "        img_array[y-1,x-1] = 1 \n",
    "    \n",
    "    #generate title\n",
    "    if title is None:\n",
    "        title = ''\n",
    "\n",
    "    #Create the figure\n",
    "    layout = go.Layout()\n",
    "    fig = go.Figure(layout=layout, data=go.Heatmap(z=img_array, colorscale='Viridis'))\n",
    "    #center title in fig\n",
    "    fig.update_layout(title=title,\n",
    "                        title_x=0.5, \n",
    "                        yaxis=dict(scaleanchor=\"x\", scaleratio=1, autorange='reversed'), \n",
    "                        xaxis=dict(scaleratio=1),\n",
    "                        plot_bgcolor='rgba(0,0,0,0)',\n",
    "                        width=600, height=600,\n",
    "                        hovermode='x')\n",
    "    fig.update_xaxes(showticklabels=False)\n",
    "    fig.update_yaxes(showticklabels=False)\n",
    "\n",
    "    #create dash app:\n",
    "    app = Dash(__name__)\n",
    "    app.layout = html.Div([\n",
    "        dcc.Graph(id=\"graph\", figure=fig, clear_on_unhover=True),\n",
    "        dcc.Tooltip(id=\"graph-tooltip\"),\n",
    "    ])\n",
    "\n",
    "    app.run_server()\n",
    "\n",
    "plot_chip_by_idx(chamber_idxs_to_keep, title='Chambers to keep for r2 of {}'.format(r2_threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Join kinetics and standard curve data\n",
    "# std_columns_tokeep = ['x', 'y','std_concs', 'std_summed_intensity', 'std_stddev_intensity', 'std_slope', \n",
    "#                       'std_intercept', 'std_r2', 'std_pvalue', 'std_stderr', 'std_slope_units', 'substrate_name', 'experimental_day', 'setup', 'device', 'assay_type', 'position']\n",
    "# kinetics_and_standards = squeezed_kinetic_data.join(fitted_standards_filtered[std_columns_tokeep])\n",
    "\n",
    "# # keep only data from chambers with standard curves with linear regression r2 values >0.98 (i.e., we don't process any data from chambers with poor standard curves)\n",
    "# kinetics_and_standards = kinetics_and_standards[kinetics_and_standards['std_r2'] > 0.98]\n",
    "# kinetics_and_standards.sort_values(by = 'std_slope').head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this next part, we'll be generating the predicted product concentration for each well, for each time, and (I think) for each concentration. That's a 3 or 4D array.\n",
    "I think we just do this by (something like) dividing by the slope for that chamber and adding the intercept - but it looks like below, they weren't adding the intercept.\n",
    "I'm too tired and will have to think about this next part tomorrow.\n",
    "\n",
    "Morning: Our standard curve relates product fluorescence to product concentration. (slope = RFU/conc) (intercept = RFU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "chamber_idxs, luminance_data, conc_data, time_data = assay_data_to_array(db_conn, 'kinetics_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 1792, 11)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "luminance_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each well contains time_series data. We have 32*56 wells (1792), and then N assays with different concentrations.\n",
    "So we have a np array with dimensions (time x wells x assays)\n",
    "For a standard, this will be (1, 1792, # concentrations)\n",
    "For a kinetics run, this will be (~20, 1792, # concentrations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "chamber_idxs, luminance_data, conc_data, time_data = assay_data_to_array(db_conn, 'kinetics_0')\n",
    "\n",
    "slopes = np.array([db_conn._json_dict['runs']['standard_0']['analyses']['linear_regression']['chambers'][chamber_idx]['slope'] for chamber_idx in chamber_idxs])\n",
    "\n",
    "#calculate product concentration by dividing every chamber intensity by the slope of the standard curve for that chamber\n",
    "product_concentration_data = luminance_data / slopes[np.newaxis, :, np.newaxis]\n",
    "\n",
    "###TODO continue from here inthe morning...\n",
    "\n",
    "\n",
    "# # use the product standard curve to convert sum chamber intensities to product concentrations and store that as a new column\n",
    "# kinetics_and_standards['chamber_product_concs'] = kinetics_and_standards.apply(lambda row: [c/row.std_slope for c in row.chamber_sum], axis = 1)\n",
    "\n",
    "# # save merged and cleaned dataframe as a csv\n",
    "# kinetics_and_standards.to_csv('3_kinetics_and_standards.csv')\n",
    "\n",
    "# # drop columns with NaNs\n",
    "# kinetics_and_standards = kinetics_and_standards.dropna()\n",
    "# kinetics_and_standards.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 251.01855984,  357.88783506,   20.62794518, ...,\n",
       "          410.380496  ,   14.12078647,  282.3487359 ],\n",
       "        [ 167.8892504 ,  236.61319314,   16.12632629, ...,\n",
       "          268.09591437,   10.58891045,  220.83811029],\n",
       "        [  76.93746703,   45.64213627,   37.42898952, ...,\n",
       "           47.34620557,   30.4525987 ,  173.1185644 ],\n",
       "        ...,\n",
       "        [  83.41297692,   43.56567955,   23.98434317, ...,\n",
       "           34.7932461 ,   15.1158788 ,  218.98474092],\n",
       "        [  87.58146763,   43.653928  ,   24.90361418, ...,\n",
       "           35.13808325,   15.70444544,  231.01681549],\n",
       "        [  94.92381224,   49.51082315,   23.6591517 , ...,\n",
       "           37.6800207 ,   14.04549181,  228.15738927]],\n",
       "\n",
       "       [[ 268.81149154,  386.17203217,   21.78376852, ...,\n",
       "          418.21604219,   12.40869345,  297.59143111],\n",
       "        [ 163.57922278,  233.23277601,   13.47762056, ...,\n",
       "          258.0743062 ,    8.91850868,  218.48739345],\n",
       "        [ 148.14891174,  102.77263041,   41.81442585, ...,\n",
       "           81.18779163,   29.16661905,  273.23908119],\n",
       "        ...,\n",
       "        [ 116.57365667,   65.02475799,   23.70542355, ...,\n",
       "           46.56569323,   14.15270315,  267.90857644],\n",
       "        [ 113.66433948,   60.37800082,   24.45901039, ...,\n",
       "           44.87162264,   14.2025831 ,  268.2908906 ],\n",
       "        [ 190.90022659,   96.07222522,   27.14632207, ...,\n",
       "           64.08043539,   14.14793539,  377.29239051]],\n",
       "\n",
       "       [[ 514.11089005,  540.93011758,   41.08222654, ...,\n",
       "          480.22062423,   27.79575661,  622.90243197],\n",
       "        [ 239.68151589,  298.60822901,   24.42127969, ...,\n",
       "          291.23199024,   18.01523635,  312.3273743 ],\n",
       "        [ 595.19229612,  275.14597409,   62.74398837, ...,\n",
       "          163.11175493,   48.55636039,  909.600005  ],\n",
       "        ...,\n",
       "        [ 407.98527512,  193.9046626 ,   45.02907589, ...,\n",
       "          118.26081116,   30.19838226,  738.8078134 ],\n",
       "        [ 364.68538445,  178.64414065,   46.4576112 , ...,\n",
       "          113.67340481,   31.01465   ,  639.14081641],\n",
       "        [ 718.95467679,  252.28918975,   49.12862455, ...,\n",
       "          141.39394639,   32.03871852, 1149.26341435]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 390.21253121,  472.16584288,   30.90714542, ...,\n",
       "          461.48996069,   16.82484828,  544.7036107 ],\n",
       "        [ 190.62340445,  253.14025875,   15.92395061, ...,\n",
       "          272.7839605 ,    9.9235455 ,  286.55015222],\n",
       "        [ 415.23619706,  216.33598351,   52.37264248, ...,\n",
       "          145.40697067,   34.84002425,  872.60704722],\n",
       "        ...,\n",
       "        [ 272.06739035,  137.30142598,   32.31851533, ...,\n",
       "           93.98935811,   17.97309514,  629.64909402],\n",
       "        [ 244.66738078,  125.49474882,   33.92639186, ...,\n",
       "           89.00984041,   19.13689953,  549.78657426],\n",
       "        [ 501.46686587,  196.66255303,   38.21917831, ...,\n",
       "          121.91063125,   19.73940138, 1097.27854468]],\n",
       "\n",
       "       [[ 260.3576089 ,  374.66948732,   20.1470266 , ...,\n",
       "          417.05999891,   12.53740174,           nan],\n",
       "        [ 164.25007788,  231.9161516 ,   13.60714606, ...,\n",
       "          261.03616211,    9.22650656,           nan],\n",
       "        [ 122.20340452,   85.03414622,   39.22280827, ...,\n",
       "           71.90120097,   29.09781504,           nan],\n",
       "        ...,\n",
       "        [ 106.00468768,   57.71572087,   23.94101664, ...,\n",
       "           42.04798173,   13.28183184,           nan],\n",
       "        [ 105.32295187,   56.06254386,   25.33500275, ...,\n",
       "           41.5718849 ,   14.1725668 ,           nan],\n",
       "        [ 161.00768971,   82.77931892,   26.30328636, ...,\n",
       "           55.34756315,   13.43292009,           nan]],\n",
       "\n",
       "       [[ 456.08381652,  515.36647771,   35.20629271, ...,\n",
       "          479.46658543,   24.62243299,           nan],\n",
       "        [ 216.50603757,  280.55160532,   18.9803217 , ...,\n",
       "          288.16159813,   15.65425714,           nan],\n",
       "        [ 513.64566273,  253.66032385,   56.01976189, ...,\n",
       "          161.53511346,   44.41591157,           nan],\n",
       "        ...,\n",
       "        [ 344.97462716,  171.81878286,   36.91411629, ...,\n",
       "          110.91045413,   26.40403533,           nan],\n",
       "        [ 307.98915428,  157.30158729,   38.82356062, ...,\n",
       "          106.79072859,   27.73324436,           nan],\n",
       "        [ 619.37760912,  231.71070503,   41.62248578, ...,\n",
       "          136.86121549,   28.74975717,           nan]]])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_concentration_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#NF where are we generating the CSVs? We need to specify filenames whenever we generate files.\n",
    "\n",
    "# clean dataframe and merge button quant data\n",
    "cleaned_kinetics_df = kinetics_and_standards.drop(\n",
    "    columns=[\n",
    "        \"x\",\n",
    "        \"y\",\n",
    "        \"chamber_median\",\n",
    "        \"chamber_stddev\",\n",
    "        \"std_concs\",\n",
    "        \"std_summed_intensity\",\n",
    "        \"std_stddev_intensity\",\n",
    "        \"std_pvalue\",\n",
    "        \"std_stderr\",\n",
    "        \"std_slope_units\",\n",
    "        \"experimental_day\",\n",
    "        \"setup\",\n",
    "        \"device\",\n",
    "        'button_sum',\n",
    "        'button_sum_bgsub'\n",
    "\n",
    "    ]\n",
    ")\n",
    "df_button = pd.read_csv(root+'/20230712_adk_orthologs_egfp_summary.csv')\n",
    "\n",
    "# add a position value that is a tuple of ints that can be sorted on numerically, unlike the \"indicies\" column, which is a string\n",
    "df_button['position'] = [(int(r['y']),int(r['x'])) for i,r in df_button.iterrows()]\n",
    "\n",
    "# merge kinetics and button quant data\n",
    "cleaned_kinetics_df = pd.merge(cleaned_kinetics_df, df_button, on='position', how='left')\n",
    "\n",
    "# clean merged dataframe of unnecessary columns etc\n",
    "cleaned_kinetics_df = cleaned_kinetics_df.drop(\n",
    "    columns=[\n",
    "        \"x\",\n",
    "        \"y\",\n",
    "        \"median_button\",\n",
    "        \"std_button\",\n",
    "        \"x_button_center\",\n",
    "        \"y_button_center\",\n",
    "        \"radius_button_disk\",\n",
    "        \"median_button_annulus\",\n",
    "        \"std_button_annulus_localBG\",\n",
    "        \"outer_radius_button_annulus\",\n",
    "        'summed_button_annulus_normed',\n",
    "        'inner_radius_button_annulus',\n",
    "        \"xslice\",\n",
    "        \"yslice\",\n",
    "        \"id_y\"\n",
    "\n",
    "    ]\n",
    ")\n",
    "cleaned_kinetics_df = cleaned_kinetics_df.rename(columns={'id_x': 'id'})\n",
    "cleaned_kinetics_df.sort_values(by = 'std_r2').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use eGFP standard curve to quantify concentration and store as a new column\n",
    "EGFP_SLOPE = 91900.03 # summed_button_BGsub/nM\n",
    "cleaned_kinetics_df['enzyme_conc_nM'] = cleaned_kinetics_df['summed_button_BGsub']/(EGFP_SLOPE)\n",
    "cleaned_kinetics_df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Fit initial rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class KineticDataException(Exception):\n",
    "    pass\n",
    "\n",
    "def divide_chunks(l, n):\n",
    "    # Function to split a list 'l' into 'n' roughly equal-sized chunks.\n",
    "    # The function yields each chunk as a separate list.\n",
    "    # It ensures that no chunk is larger than the original list.\n",
    "    n = math.ceil(len(l) / float(n))\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]\n",
    "\n",
    "def mm_model(x, v_max, Km):\n",
    "    # Michaelis-Menten equation to model enzyme kinetics.\n",
    "    # 'x': substrate concentration, 'v_max': maximum reaction rate, 'Km': Michaelis constant.\n",
    "    return v_max * x / (x + Km)\n",
    "\n",
    "\n",
    "def compute_initial_reaction_slope(time_arr: np.array, \n",
    "                                   signal_arr: np.array,\n",
    "                                  min_included_percent: int = 2): \n",
    "    \"\"\"\n",
    "    Determines best linear fit to initial slope of data, by fitting regressions to \n",
    "    all percentiles of the data--greater than some defined minimum--anchored at the origin.\n",
    "    \n",
    "    Args:\n",
    "        time_arr (np.array): array of assay read times\n",
    "        signal_arr (np.array): array of kinetic signal readouts\n",
    "        min_included_percent (int) = 5: minimum percent of data to be included \n",
    "    \n",
    "    Returns:\n",
    "        slope, intercept, score ((float, float, float)): fit parameters of best fit\n",
    "        \n",
    "    \"\"\"\n",
    "    # Need to triage further for different definitions of minimum\n",
    "    MIN_INCLUDED_DATA_POINTS = 3\n",
    "    \n",
    "    perc_concs = list(divide_chunks(signal_arr, 100))\n",
    "    perc_times = list(divide_chunks(time_arr, 100))\n",
    " \n",
    "    scores = []\n",
    "    slopes = [] \n",
    "    intercepts = []\n",
    "    \n",
    "    min_inclusion = max(len(perc_times) * min_included_percent // 100, MIN_INCLUDED_DATA_POINTS)\n",
    "    \n",
    "    for i in range(len(perc_times), min_inclusion, -1):\n",
    "        curr_times = np.concatenate(perc_times[:i])\n",
    "        curr_concs = np.concatenate(perc_concs[:i])\n",
    "        reg = LinearRegression().fit(np.array(curr_times).reshape(-1,1), curr_concs)\n",
    "        curr_score = reg.score(np.array(curr_times).reshape(-1,1), curr_concs)\n",
    "        scores.append(curr_score)\n",
    "        slopes.append(reg.coef_)\n",
    "        intercepts.append(reg.intercept_)\n",
    "    \n",
    "    if len(scores) == 0 and min_included_percent == 100:\n",
    "        reg = LinearRegression().fit(np.array(perc_times).reshape(-1,1), perc_concs)\n",
    "        curr_score = reg.score(np.array(perc_times).reshape(-1,1), perc_concs)\n",
    "        return reg.coef_.item(), reg.intercept_.item(), curr_score\n",
    "\n",
    "    # The fit with the highest R-squared value is selected as the best fit.\n",
    "    max_r2_idx = np.argmax(scores)\n",
    "    \n",
    "    if scores[max_r2_idx] < 0.9:\n",
    "        return np.array([np.nan]), np.array([np.nan]), np.array([np.nan])\n",
    "    \n",
    "    return slopes[max_r2_idx], intercepts[max_r2_idx], scores[max_r2_idx]\n",
    "\n",
    "\n",
    "def get_scoop_filter_index(times: list, data: list):\n",
    "    # Find the index to filter data to remove the initial scooping artifact in kinetic measurements.\n",
    "    # The scooping artifact is the region where the curve decreases at the beginning of the reaction.\n",
    "    rate_of_change = np.array(data[1:]) - np.array(data[:-1])\n",
    "    try:\n",
    "        last_negative_index = np.where(rate_of_change < 0)[0][-1] + 1\n",
    "    except IndexError:\n",
    "        last_negative_index = 0\n",
    "    duration = max(times) - min(times)\n",
    "    max_time_cutoff = np.where(np.array(times) < (duration / 3))[0][-1]\n",
    "\n",
    "    return min(last_negative_index, max_time_cutoff)\n",
    "\n",
    "   \n",
    "def fit_kinetics_linear(row):\n",
    "    # Fit linear models to the initial slope of the kinetic data for each row (reaction) in the dataset.\n",
    "    # The function uses 'compute_initial_reaction_slope' to compute the initial slope fit,\n",
    "    # and 'get_scoop_filter_index' to determine the index to filter out the scooping artifact.\n",
    "    # It returns slope, intercept, and R-squared values for both the entire reaction and the filtered part.\n",
    "    try:\n",
    "        slope, intercept, score = compute_initial_reaction_slope(row['time_s'],row['chamber_product_concs'])\n",
    "    except ValueError:\n",
    "        \n",
    "        slope = np.array([np.nan])\n",
    "        intercept = np.array([np.nan])\n",
    "        score = np.array([np.nan])\n",
    "            \n",
    "    filter_scoop_index = get_scoop_filter_index(row['time_s'],row['chamber_product_concs'])\n",
    "    try:\n",
    "        filter_slope, filter_intercept, filter_score = compute_initial_reaction_slope(row['time_s'][filter_scoop_index:],row['chamber_product_concs'][filter_scoop_index:])\n",
    "    except ValueError:\n",
    "        \n",
    "        filter_slope = np.array([np.nan])\n",
    "        filter_intercept = np.array([np.nan])\n",
    "        filter_score = np.array([np.nan])\n",
    "    return slope.item(), intercept.item(), score.item()**2, filter_slope.item(), filter_intercept.item(), filter_score.item()**2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fit an initial rate for each reaction\n",
    "cleaned_kinetics_df[['initial_rate', 'intercepts', 'initial_rate_r2', 'filter_initial_rate', 'filter_intercepts', 'filter_initial_rate_r2']] = cleaned_kinetics_df.apply(fit_kinetics_linear, axis=1, result_type='expand')\n",
    "cleaned_kinetics_df.sort_values(by = 'position').head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save fit initial rates to a .csv\n",
    "cleaned_kinetics_df.to_csv('4_fit_initial_rates.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Filter initial rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Need to decided on some standard filtering criteria for experiments\n",
    "# drop rows with initial rates =< 0\n",
    "cleaned_kinetics_df_filtered = cleaned_kinetics_df[cleaned_kinetics_df['initial_rate'] > 0]\n",
    "\n",
    "#drop rows with poor standard curves\n",
    "cleaned_kinetics_df_filtered = cleaned_kinetics_df_filtered[cleaned_kinetics_df_filtered['std_r2'] > 0.98]\n",
    "\n",
    "#drop rows with poor expression\n",
    "cleaned_kinetics_df_filtered = cleaned_kinetics_df_filtered[cleaned_kinetics_df_filtered['enzyme_conc_nM'] > 1.5]\n",
    "\n",
    "#drop flagged rows\n",
    "cleaned_kinetics_df_filtered = cleaned_kinetics_df_filtered[cleaned_kinetics_df_filtered['mm_tofit_mask'] == True]\n",
    "\n",
    "#drop rows with poor initial rate fits\n",
    "cleaned_kinetics_df_filtered = cleaned_kinetics_df_filtered[cleaned_kinetics_df_filtered['filter_initial_rate_r2'] > 0.8]\n",
    "\n",
    "cleaned_kinetics_df_filtered =cleaned_kinetics_df_filtered.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NF: Remove this, replace with visualization + flags.\n",
    "\n",
    "#manually inspect button quant image and exclude those with issues (positions are inverted from whats on the button summary image)\n",
    "to_drop = [(8,26),\n",
    "          (11,23),\n",
    "          (25,5),\n",
    "          (24,4),\n",
    "          (25,4),\n",
    "          (31,1),\n",
    "          (28,1),\n",
    "          (22,1),\n",
    "          (21,1),\n",
    "          (20,1),\n",
    "          (19,1),\n",
    "          (17,1),\n",
    "          (12,1),\n",
    "          (11,1),\n",
    "          (9,1),\n",
    "          (4,1),\n",
    "          (3,1),\n",
    "          (3,32),\n",
    "          (51,32),\n",
    "          (53,32),\n",
    "          (55,32),\n",
    "          (56,32),\n",
    "          ]\n",
    "\n",
    "cleaned_kinetics_df_filtered = cleaned_kinetics_df_filtered.loc[~cleaned_kinetics_df_filtered['position'].isin(to_drop)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save fit filtered initial rates to a .csv\n",
    "cleaned_kinetics_df_filtered.to_csv('5_filtered_initial_rates.csv')\n",
    "cleaned_kinetics_df_filtered.head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit Michalis-Menten curves and visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes a DataFrame of initial rates at different substrate concentrations as input and compresses these values \n",
    "# into a single row pr chamber by returning a series where initial rate values and substrate concentrations are each a list\n",
    "def squeeze_initial_rates(df):\n",
    "    # Create a copy of the input DataFrame and sort it based on 'substrate_conc' column.\n",
    "    dfcopy = df.copy().sort_values('substrate_conc')\n",
    "    \n",
    "    # Extract relevant data from the first row of the sorted DataFrame.\n",
    "    # These values are assumed to be the same for all rows in the group.\n",
    "    chamber_id = dfcopy.iloc[0]['id']\n",
    "    position = dfcopy.iloc[0]['position']\n",
    "    times = dfcopy.iloc[0]['time_s']\n",
    "    sum_chamber = dfcopy.iloc[0]['chamber_sum']\n",
    "    std_slope = dfcopy.iloc[0]['std_slope']\n",
    "    std_r2 = dfcopy.iloc[0]['std_r2']\n",
    "    substrate_name = dfcopy.iloc[0]['substrate_name']\n",
    "    assay_type = dfcopy.iloc[0]['assay_type']\n",
    "    chamber_product_concs = dfcopy.iloc[0]['chamber_product_concs']\n",
    "    summed_button = dfcopy.iloc[0]['summed_button']\n",
    "    summed_button_BGsub = dfcopy.iloc[0]['summed_button_BGsub']\n",
    "    enzyme_conc_nM = dfcopy.iloc[0]['enzyme_conc_nM']\n",
    "    \n",
    "    # Insert zeros at the beginning of initial rate and substrate_conc columns to anchor our michaelis menten curves at 0,0.\n",
    "    substrate_conc = np.insert(dfcopy.substrate_conc.values.tolist(),0,0,axis = 0)\n",
    "    initial_rate = np.insert(dfcopy.initial_rate.values.tolist(),0,0,axis =0)\n",
    "    intercepts = np.insert(dfcopy.intercepts.values.tolist(), 0,0,axis = 0)\n",
    "    initial_rate_r2 = np.insert(dfcopy.initial_rate_r2.values.tolist(),0,0,axis = 0)\n",
    "\n",
    "    filter_initial_rate = np.insert(dfcopy.filter_initial_rate.values.tolist(),0,0,axis=0)\n",
    "    filter_intercepts = np.insert(dfcopy.filter_intercepts.values.tolist(), 0,0,axis = 0)\n",
    "    filter_initial_rate_r2 = np.insert(dfcopy.filter_initial_rate_r2.values.tolist(),0,0,axis = 0)\n",
    "    \n",
    "    # Create a new pandas Series to store the extracted data.\n",
    "    squeezed_series = pd.Series(data = [chamber_id, times, sum_chamber, std_slope, std_r2, substrate_name, assay_type,chamber_product_concs,\n",
    "                                        summed_button,summed_button_BGsub, substrate_conc, initial_rate, intercepts, initial_rate_r2, \n",
    "                                        filter_initial_rate, filter_intercepts, filter_initial_rate_r2, enzyme_conc_nM],\n",
    "                               index = ['id', 'time_s', 'sum_chamber', 'std_slope', 'std_r2', 'substrate_name', 'assay_type', 'chamber_product_concs', \n",
    "                                        'summed_button', 'summed_button_BGsub', 'substrate_conc', 'initial_rate', 'intercept', 'initial_rate_r2', \n",
    "                                        'filter_initial_rate', 'filter_intercepts', 'filter_initial_rate_r2','enzyme_conc_nM'])\n",
    "    return squeezed_series\n",
    "\n",
    "\n",
    "# Group the 'cleaned_kinetics_df_filtered' DataFrame by 'position' and apply 'squeeze_initial_rates' function to each group.\n",
    "squeezed_cleaned_fltered_kinetic_data = cleaned_kinetics_df_filtered.groupby('position').apply(squeeze_initial_rates).reset_index()\n",
    "squeezed_cleaned_fltered_kinetic_data.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_MM_by_chamber(row):\n",
    "    #define the minimum number of initial rates needed to fit a michaelis menten curve. I usually expect 5 or 6.\n",
    "    if len(row['initial_rate']) >5:\n",
    "        try:\n",
    "            params, _ = curve_fit(mm_model, np.insert(row['substrate_conc'], 0, 0), np.insert(row['initial_rate'], 0, 0) , p0=[np.median(row['substrate_conc']), np.max(row['initial_rate'])])\n",
    "            vmax = params[0]\n",
    "            km = params[1]\n",
    "        except TypeError: \n",
    "            print(\"Could not fit\")\n",
    "            vmax = np.nan\n",
    "            km = np.nan\n",
    "    \n",
    "\n",
    "        try:\n",
    "            params, _ = curve_fit(mm_model, np.insert(row['substrate_conc'],0,0), np.insert(row['filter_initial_rate'],0,0) , p0=[np.median(row['substrate_conc']), np.max(row['filter_initial_rate'])])\n",
    "            vmax_filter = params[0]\n",
    "            km_filter = params[1]\n",
    "        except TypeError: \n",
    "            print(\"Could not fit\")\n",
    "            vmax_filter = np.nan\n",
    "            km_filter = np.nan\n",
    "    \n",
    "    \n",
    "    else:\n",
    "        vmax = np.nan\n",
    "        km = np.nan\n",
    "        vmax_filter = np.nan\n",
    "        km_filter = np.nan\n",
    "        \n",
    "    return vmax, km, vmax_filter, km_filter\n",
    "\n",
    "squeezed_cleaned_fltered_kinetic_data[['vmax', 'km', 'vmax_filter', 'km_filter']] = squeezed_cleaned_fltered_kinetic_data.apply(fit_MM_by_chamber, axis=1, result_type='expand')\n",
    "squeezed_cleaned_fltered_kinetic_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Idea: Once we have initial fit for KM, have a view that flags each well by substrate \"coverage\":\n",
    "#that is, whether our experiment had 1/10th and 10x substrate concentration than Vmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract kcat from vmax\n",
    "squeezed_cleaned_fltered_kinetic_data['kcat'] = squeezed_cleaned_fltered_kinetic_data['vmax'].div((squeezed_cleaned_fltered_kinetic_data['enzyme_conc_nM']/1000))\n",
    "squeezed_cleaned_fltered_kinetic_data['kcat_filtered'] = squeezed_cleaned_fltered_kinetic_data['vmax_filter'].div((squeezed_cleaned_fltered_kinetic_data['enzyme_conc_nM']/1000))\n",
    "squeezed_cleaned_fltered_kinetic_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save michaelis menten fits to .csv\n",
    "squeezed_cleaned_fltered_kinetic_data.to_csv('6_mm_fits_unfiltered.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out outliers for each variant\n",
    "MM_outliers_removed = squeezed_cleaned_fltered_kinetic_data.copy()\n",
    "\n",
    "def filter_outliers(group, z_threshold = 1.5):\n",
    "    z_scores = (group - group.mean()) / group.std()\n",
    "    return group[abs(z_scores) <= z_threshold]\n",
    "\n",
    "# Define the columns for filtering\n",
    "columns = ['enzyme_conc_nM', 'kcat', 'km'] #I also filtered on kcat and Km to exclude some bizarre fits that were unbounded\n",
    "\n",
    "for column in columns:\n",
    "    MM_outliers_removed[column + '_z_filtered'] = MM_outliers_removed.groupby('id')[column].transform(filter_outliers)\n",
    "    \n",
    "MM_outliers_removed = MM_outliers_removed.dropna()\n",
    "MM_outliers_removed.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save filtered michaelis menten fits to .csv\n",
    "MM_outliers_removed.to_csv('7_mm_fits_filtered.csv')\n",
    "MM_outliers_removed.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Note: plot chip by R2 of exponential fit, then show individual graphs\n",
    "#Or, do same just by linear fit.\n",
    "\n",
    "#plot michaelis menten curves by variant/id\n",
    "\n",
    "# Group the data by 'id' column\n",
    "groups = MM_outliers_removed.groupby('id')\n",
    "\n",
    "# Calculate the number of rows and columns\n",
    "num_groups = len(groups)\n",
    "num_columns = 4\n",
    "num_rows, remaining = divmod(num_groups, num_columns)\n",
    "if remaining > 0:\n",
    "    num_rows += 1\n",
    "\n",
    "#print(groups)\n",
    "\n",
    "# Create a figure and subplots\n",
    "fig, axs = plt.subplots(num_rows, num_columns, figsize=(15, 4*num_rows), sharex=True)\n",
    "\n",
    "# Iterate over the groups and plot the data on separate subplots\n",
    "for i, (ortholog_name, ortholog_data) in enumerate(groups):\n",
    "    # Get the corresponding subplot for the current group\n",
    "    ax = axs.flat[i]\n",
    "    vmax_norm_ave = []\n",
    "    # Plot the data for the current group\n",
    "    for _, row in ortholog_data.iterrows():\n",
    "        ax.scatter(row['substrate_conc'], [(v/(row['enzyme_conc_nM']/1000)) for v in row['initial_rate']], label=row['position'])\n",
    "        x = np.linspace(0, 16000, 1000)\n",
    "        ax.plot(x, mm_model(x, row['kcat'], row['km']))\n",
    "    \n",
    "    # Set labels and title for the subplot\n",
    "    ax.set_xlabel('Substrate Concentration (M)')\n",
    "    ax.set_ylabel('Initial Rate/[E] ($s^{-1}$)')\n",
    "    ax.set_title(f'{ortholog_name}')\n",
    "    \n",
    "    # Show the legend for the subplot\n",
    "    ax.legend(fontsize='small')\n",
    "    ax.legend()\n",
    "\n",
    "# Adjust spacing between subplots\n",
    "fig.tight_layout()\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "\n",
    "# plt.savefig('{}.pdf'.format('MM_curves_unfiltered_initial_rate'), format='pdf')\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes a DataFrame of michaelis menten parameters for different chambers as input and compresses these values \n",
    "# into a single row per variant by returning a series where michaelis menten parameters are each a list\n",
    "\n",
    "def squeeze_replicates(df):\n",
    "    # Create a copy of the input DataFrame and sort it based on 'id' column.\n",
    "    dfcopy = df.copy().sort_values('id')\n",
    "    \n",
    "    # Extract relevant information that is assumed to be the same for all rows within the group.\n",
    "    substrate_name = dfcopy.iloc[0]['substrate_name']\n",
    "    assay_type = dfcopy.iloc[0]['assay_type']\n",
    "\n",
    "    # Calculate the number of replicates in the group.\n",
    "    replicates = dfcopy.shape[0]\n",
    "\n",
    "    # Extract specific column data as lists for each replicate within the group.\n",
    "    summed_button = dfcopy.summed_button.values.tolist()\n",
    "    summed_button_BGsub = dfcopy.summed_button_BGsub.values.tolist()\n",
    "    positions = dfcopy.position.values.tolist()\n",
    "    substrate_conc = dfcopy.substrate_conc.values.tolist()\n",
    "    initial_rate = dfcopy.initial_rate.values.tolist()\n",
    "    initial_rate_r2 = dfcopy.initial_rate_r2.values.tolist()\n",
    "    vmax = dfcopy.vmax.values.tolist()\n",
    "    km = dfcopy.km.values.tolist()\n",
    "    vmax_filter = dfcopy.vmax_filter.values.tolist()\n",
    "    km_filter = dfcopy.km_filter.values.tolist()\n",
    "    kcat = dfcopy.kcat.values.tolist()\n",
    "    kcat_filtered = dfcopy.kcat_filtered.values.tolist()\n",
    "    enzyme_conc_nM = dfcopy.enzyme_conc_nM.values.tolist()\n",
    "\n",
    "    # Create a new pandas Series to store the extracted data for all replicates within the group.\n",
    "    squeezed_series = pd.Series(data = [substrate_name, assay_type, summed_button, summed_button_BGsub, positions, substrate_conc, initial_rate, initial_rate_r2, vmax, km, vmax_filter, km_filter, kcat, kcat_filtered,enzyme_conc_nM, replicates],\n",
    "                               index = ['substrate_name', 'assay_type', 'summed_button', 'summed_button_BGsub', 'positions', 'substrate_conc', 'initial_rate', 'initial_rate_r2', 'vmax', 'km', 'vmax_filter', 'km_filter', 'kcat', 'kcat_filtered','enzyme_conc_nM', 'replicates'])\n",
    "    return squeezed_series\n",
    "\n",
    "# Group the DataFrame by 'id' and apply 'squeeze_replicates' function to each group of replicates.\n",
    "squeezed_MM_data = MM_outliers_removed.groupby('id').apply(squeeze_replicates).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate various statistics related to Michaelis-Menten (MM) kinetic parameters.\n",
    "# The function takes a row (replicate) from the DataFrame as input and returns calculated statistics.\n",
    "\n",
    "def MM_stats(row):\n",
    "    \n",
    "    # Function to calculate the interquartile range (IQR) of a given data array.\n",
    "    def IQR(data):\n",
    "        q1 = np.percentile(data, 25)\n",
    "        q3 = np.percentile(data, 75)\n",
    "    \n",
    "        # Calculate the interquartile range (IQR)\n",
    "        iqr = q3 - q1\n",
    "        return iqr\n",
    "\n",
    "\n",
    "        \n",
    "    # Extract relevant data for calculations from the row (set of replicates).\n",
    "    summed_button = row['summed_button']\n",
    "    vmax = row['vmax']\n",
    "    vmax_filter = row['vmax_filter']\n",
    "    \n",
    "    kcats = row['kcat']\n",
    "    kcats_filtered = row['kcat_filtered']\n",
    "    vmaxs = row['vmax']\n",
    "    vmaxs_filter = row['vmax_filter']\n",
    "\n",
    "    # Calculate various statistics for kcat, Km, and vmax parameters and enzyme concentration.\n",
    "    kcat_mean = np.mean(kcats)\n",
    "    kcat_stdev = np.std(kcats)\n",
    "    kcat_median = np.median(kcats)\n",
    "    kcat_iqr = IQR(kcats)\n",
    "\n",
    "    kcat_mean_filtered = np.mean(kcats_filtered)\n",
    "    kcat_stdev_filtered = np.std(kcats_filtered)\n",
    "    kcat_median_filtered = np.median(kcats_filtered)\n",
    "    kcat_iqr_filtered = IQR(kcats_filtered)\n",
    "\n",
    "    Km_mean = np.mean(row['km'])\n",
    "    Km_stdev = np.std(row['km'])\n",
    "    Km_median = np.median(row['km'])\n",
    "    Km_iqr = IQR(row['km'])\n",
    "\n",
    "    Km_mean_filtered = np.mean(row['km_filter'])\n",
    "    Km_stdev_filtered = np.std(row['km_filter'])\n",
    "    Km_median_filtered = np.median(row['km_filter'])\n",
    "    Km_iqr_filtered = IQR(row['km_filter'])\n",
    "\n",
    "    vmax_mean = np.mean(vmaxs)\n",
    "    vmax_stdev = np.std(vmaxs)\n",
    "    vmax_median = np.median(vmaxs)\n",
    "    vmax_iqr = IQR(vmaxs)\n",
    "\n",
    "    vmax_mean_filtered = np.mean(vmaxs_filter)\n",
    "    vmax_stdev_filtered = np.std(vmaxs_filter)\n",
    "    vmax_median_filtered = np.median(vmaxs_filter)\n",
    "    vmax_iqr_filtered = IQR(vmaxs_filter)\n",
    "\n",
    "    enzyme_conc_nM_mean = np.mean(row['enzyme_conc_nM'])\n",
    "    enzyme_conc_nM_stdev = np.std(row['enzyme_conc_nM'])\n",
    "    \n",
    "    return kcat_mean, kcat_stdev, kcat_median, kcat_iqr, Km_mean, Km_stdev, Km_median, Km_iqr, kcat_mean_filtered, kcat_stdev_filtered, kcat_median_filtered, kcat_iqr_filtered, Km_mean_filtered, Km_stdev_filtered, Km_median_filtered, Km_iqr_filtered, enzyme_conc_nM_mean, enzyme_conc_nM_stdev,vmax_mean, vmax_stdev, vmax_median, vmax_iqr, vmax_mean_filtered, vmax_stdev_filtered, vmax_median_filtered, vmax_iqr_filtered\n",
    "    \n",
    "\n",
    "squeezed_MM_data[['kcat_mean', 'kcat_stdev', 'kcat_median', 'kcat_iqr', 'Km_mean', 'Km_stdev', 'Km_median', 'Km_iqr', 'kcat_mean_filtered', \n",
    "                  'kcat_stdev_filtered', 'kcat_median_filtered', 'kcat_iqr_filtered', 'Km_mean_filtered', 'Km_stdev_filtered', 'Km_median_filtered', \n",
    "                  'Km_iqr_filtered', 'enzyme_conc_nM_mean','enzyme_conc_nM_stdev', 'vmax_mean', 'vmax_stdev', 'vmax_median', 'vmax_iqr', 'vmax_mean_filtered', \n",
    "                 'vmax_stdev_filtered', 'vmax_median_filtered', 'vmax_iqr_filtered']] = squeezed_MM_data.apply(MM_stats, axis=1, result_type='expand')\n",
    "squeezed_MM_data.head(10)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#clean up dataframe\n",
    "cleaned_MM = squeezed_MM_data.drop(\n",
    "    columns=[\n",
    "        \"summed_button\",\n",
    "        \"summed_button_BGsub\",\n",
    "        \"positions\",\n",
    "        \"initial_rate\",\n",
    "        \"initial_rate_r2\",\n",
    "        \"vmax\", \n",
    "        \"km\", \n",
    "        \"substrate_conc\",\n",
    "        \"vmax_filter\",\n",
    "        \"km_filter\",\n",
    "        \"kcat\",\n",
    "        \"kcat_filtered\",\n",
    "        \"enzyme_conc_nM\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "cleaned_MM.sort_values(by = 'kcat_median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add organism name to each row\n",
    "def org_name(row):\n",
    "    #with open(\"/Users/margauxpinney/code/lab-notebook-pinney/20230629/adkLibrary_original.fasta\", 'r') as lib_file:\n",
    "    with open(root+'/adkLibrary_original.fasta', 'r') as lib_file:\n",
    "        orth_dict = {}\n",
    "        for line in lib_file.readlines():\n",
    "            if line[0] == \">\":\n",
    "            \n",
    "                org_name = line.split(\"|\")[2]\n",
    "        \n",
    "                abbrev = f\"{org_name[0].upper()}_{org_name.split('_')[-1][:4]}_ADK\"\n",
    "                orth_dict[abbrev] = org_name\n",
    "    orth_dict['bsADK'] = 'bacillus_subtilis'\n",
    "    orth_dict['gsADK'] = 'geobacillus_stearothermophilus'\n",
    "    orth_dict['bmADK'] = 'bacillus_marinus'\n",
    "    orth_dict['Sym_ther_ADK'] = 'symbiobacterium_thermophilum'\n",
    "    orth_dict['mpADK'] = 'mesotoga_prima'\n",
    "    orth_dict['miADK'] = 'mesotoga_infera'\n",
    "    orth_dict['ecADK_HTA'] = 'escherichia_coli_heat_adapted'\n",
    "    \n",
    "    \n",
    "    \n",
    "    try:\n",
    "        name = orth_dict[row['id']]\n",
    "    except:\n",
    "        name = '-'\n",
    "        \n",
    "    return name\n",
    "    \n",
    "    \n",
    "cleaned_MM['name'] = cleaned_MM.apply(org_name, axis=1)\n",
    "\n",
    "cleaned_MM.sort_values(by = 'kcat_median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the optimal growth temperature to each row\n",
    "temperature_table = pd.read_table(\"temperature_data_full.tsv\", header=0)\n",
    "temperature_table = temperature_table[[\"organism\", \"temperature\"]]\n",
    "\n",
    "MM_final = pd.merge(cleaned_MM, temperature_table, left_on = 'name', right_on = 'organism', how = 'left').drop(columns = 'name').sort_values(by='kcat_mean')\n",
    "MM_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the final table of michaelis menten parameters to a .csv\n",
    "MM_final.to_csv('8_Final_MM_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MM_final.shape[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
